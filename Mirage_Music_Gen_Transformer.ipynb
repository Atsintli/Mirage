{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj3172jgQvPp",
        "outputId": "189651be-cb5c-43c5-b30a-1c3ca8c8e345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
            "Downloading jellyfish-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (356 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.9/356.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jellyfish\n",
            "Successfully installed jellyfish-1.2.0\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.4.0\n",
            "Collecting samplings\n",
            "  Downloading samplings-0.1.7-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading samplings-0.1.7-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: samplings\n",
            "Successfully installed samplings-0.1.7\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install jellyfish\n",
        "!pip install unidecode\n",
        "!pip install samplings\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/tunesformer-main/')  # Cambia el directorio\n",
        "print(os.getcwd())    # Muestra el directorio actual, debe salir /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWQbQODIUXBz",
        "outputId": "5c6856a8-dd90-4748-bae7-a0560afab3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/tunesformer-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.Popen('generate.py', stdout=subprocess.PIPE, shell=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGBrr_aJitdW",
        "outputId": "f533041a-873e-443d-90ed-baf3754fe415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: 'generate.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BatchConverter.py\n",
        "import os\n",
        "import math\n",
        "import subprocess\n",
        "from tqdm import trange\n",
        "from multiprocessing import Pool\n",
        "\n",
        "class suppress_stdout_stderr(object):\n",
        "    '''\n",
        "    A context manager for doing a \"deep suppression\" of stdout and stderr in\n",
        "    Python, i.e. will suppress all print, even if the print originates in a\n",
        "    compiled C/Fortran sub-function.\n",
        "       This will not suppress raised exceptions, since exceptions are printed\n",
        "    to stderr just before a script exits, and after the context manager has\n",
        "    exited (at least, I think that is why it lets exceptions through).\n",
        "\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        # Open a pair of null files\n",
        "        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n",
        "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
        "        self.save_fds = (os.dup(1), os.dup(2))\n",
        "\n",
        "    def __enter__(self):\n",
        "        # Assign the null pointers to stdout and stderr.\n",
        "        os.dup2(self.null_fds[0], 1)\n",
        "        os.dup2(self.null_fds[1], 2)\n",
        "\n",
        "    def __exit__(self, *_):\n",
        "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
        "        os.dup2(self.save_fds[0], 1)\n",
        "        os.dup2(self.save_fds[1], 2)\n",
        "        # Close the null files\n",
        "        os.close(self.null_fds[0])\n",
        "        os.close(self.null_fds[1])\n",
        "\n",
        "def run_filter(lines):\n",
        "    score = \"\"\n",
        "    for line in lines.replace(\"\\r\", \"\").split(\"\\n\"):\n",
        "        if line[:2] in ['A:', 'B:', 'C:', 'D:', 'F:', 'G', 'H:', 'N:', 'O:', 'R:', 'r:', 'S:', 'T:', 'V:', 'W:', 'w:', 'X:', 'Z:'] \\\n",
        "        or line=='\\n' \\\n",
        "        or line.startswith('%'):\n",
        "            continue\n",
        "        else:\n",
        "            if '%' in line:\n",
        "                line = line.split('%')\n",
        "                bar = line[-1]\n",
        "                line = ''.join(line[:-1])\n",
        "            score += line + '\\n'\n",
        "\n",
        "    return score.strip()\n",
        "\n",
        "cmd = 'cd '+os.getcwd()\n",
        "output = os.popen(cmd).read()\n",
        "cmd = 'python data_curation/xml2abc.py -m 2 -c 6 -x '\n",
        "\n",
        "def convert_abc(file_list):\n",
        "    for file_idx in trange(len(file_list)):\n",
        "        file = file_list[file_idx]\n",
        "        filename = file.split('/')[-1]\n",
        "        try:\n",
        "            p = subprocess.Popen(cmd+'\"'+file+'\"', stdout=subprocess.PIPE, shell=True)\n",
        "            result = p.communicate()\n",
        "            output = result[0].decode('utf-8')\n",
        "            #print(output)\n",
        "            output = run_filter(output)\n",
        "            if output=='':\n",
        "                continue\n",
        "            else:\n",
        "                with open('data_curation/abc/'+filename.split('.')[-2]+'.txt', 'w', encoding='utf-8') as f:\n",
        "                    f.write(output)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    file_list = []\n",
        "    abc_list = []\n",
        "\n",
        "    # traverse folder\n",
        "    for root, dirs, files in os.walk('data_curation/xmls'):\n",
        "        for file in files:\n",
        "            filename = os.path.join(root, file)\n",
        "            file_list.append(filename)\n",
        "\n",
        "    # convert_abc(file_list)\n",
        "    file_lists = []\n",
        "    for i in range(os.cpu_count()):\n",
        "        start_idx = int(math.floor(i*len(file_list)/os.cpu_count()))\n",
        "        end_idx = int(math.floor((i+1)*len(file_list)/os.cpu_count()))\n",
        "        file_lists.append(file_list[start_idx:end_idx])\n",
        "\n",
        "    cnt = 0\n",
        "\n",
        "    for file_list in file_lists:\n",
        "        cnt += len(file_list)\n",
        "\n",
        "    pool = Pool(processes=os.cpu_count())\n",
        "    pool.map(convert_abc, file_lists)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8plFu56dRpCW",
        "outputId": "334e2c02-f48a-418e-953e-380b8b0e363c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:30<00:00,  1.16it/s]\n",
            "100%|██████████| 35/35 [00:30<00:00,  1.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "import jellyfish\n",
        "from tqdm import tqdm\n",
        "from unidecode import unidecode\n"
      ],
      "metadata": {
        "id": "LEeHlaRtYZBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import hashlib\n",
        "from tqdm import tqdm\n",
        "\n",
        "def clean_metadata(content):\n",
        "    \"\"\"Limpia metadata duplicada y mantiene solo la información esencial\"\"\"\n",
        "    lines = content.split('\\n')\n",
        "    metadata = {}\n",
        "\n",
        "    for line in lines:\n",
        "        if len(line) > 1 and line[0].isalpha() and line[1] == ':':\n",
        "            key = line[0]\n",
        "            value = line[2:].strip()\n",
        "\n",
        "            # Mantener solo el primer valor para evitar duplicados\n",
        "            if key not in metadata:\n",
        "                metadata[key] = value\n",
        "\n",
        "    # Orden específico para metadata esencial\n",
        "    essential_keys = ['X', 'T', 'C', 'L', 'M', 'K']\n",
        "    clean_metadata = []\n",
        "\n",
        "    for key in essential_keys:\n",
        "        if key in metadata:\n",
        "            clean_metadata.append(f\"{key}:{metadata[key]}\")\n",
        "\n",
        "    return '\\n'.join(clean_metadata)\n",
        "\n",
        "def generate_piece_id(content):\n",
        "    \"\"\"Genera un ID único para la pieza basado en el contenido\"\"\"\n",
        "    # Usar título y compositor para generar ID único\n",
        "    title = \"\"\n",
        "    composer = \"\"\n",
        "\n",
        "    lines = content.split('\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('T:'):\n",
        "            title = line[2:].strip()\n",
        "            break\n",
        "    for line in lines:\n",
        "        if line.startswith('C:'):\n",
        "            composer = line[2:].strip()\n",
        "            break\n",
        "\n",
        "    # Generar hash corto del contenido combinado\n",
        "    combined = f\"{title}_{composer}\"\n",
        "    hash_obj = hashlib.md5(combined.encode())\n",
        "    return hash_obj.hexdigest()[:8]\n",
        "\n",
        "def extract_voice_info(content):\n",
        "    \"\"\"Extrae información específica de cada voz\"\"\"\n",
        "    voices = {}\n",
        "    lines = content.split('\\n')\n",
        "    current_voice = None\n",
        "\n",
        "    for line in lines:\n",
        "        # Detectar definición de voz\n",
        "        if line.startswith('V:'):\n",
        "            voice_match = re.search(r'V:(\\d+)', line)\n",
        "            if voice_match:\n",
        "                voice_num = voice_match.group(1)\n",
        "                current_voice = voice_num\n",
        "\n",
        "                voices[voice_num] = {\n",
        "                    'voice_id': f\"V{voice_num}\",\n",
        "                    'content': [],\n",
        "                    'definition_line': line\n",
        "                }\n",
        "\n",
        "        # Agregar contenido musical a la voz actual\n",
        "        elif current_voice and current_voice in voices:\n",
        "            # Solo agregar líneas con contenido musical\n",
        "            if line.strip() and not (len(line) > 1 and line[0].isalpha() and line[1] == ':'):\n",
        "                if not line.startswith('V:') and not line.startswith('%'):\n",
        "                    voices[current_voice]['content'].append(line)\n",
        "\n",
        "    return voices\n",
        "\n",
        "def count_measures_in_voice(voice_content):\n",
        "    \"\"\"Cuenta compases en el contenido de una voz específica\"\"\"\n",
        "    if not voice_content:\n",
        "        return 0\n",
        "    content = ' '.join(voice_content)\n",
        "    # Contar barras de compás\n",
        "    bar_count = content.count('|')\n",
        "    return max(1, bar_count)\n",
        "\n",
        "def split_voice_content(voice_content, max_measures=32):\n",
        "    \"\"\"Divide el contenido de una voz en segmentos manejables\"\"\"\n",
        "    if not voice_content:\n",
        "        return [voice_content]\n",
        "\n",
        "    measures_count = count_measures_in_voice(voice_content)\n",
        "\n",
        "    if measures_count <= max_measures:\n",
        "        return [voice_content]\n",
        "\n",
        "    # Dividir por líneas y contar medidas acumulativas\n",
        "    segments = []\n",
        "    current_segment = []\n",
        "    current_measures = 0\n",
        "\n",
        "    for line in voice_content:\n",
        "        line_measures = line.count('|')\n",
        "\n",
        "        # Si agregar esta línea excede el límite, iniciar nuevo segmento\n",
        "        if current_measures + line_measures > max_measures and current_segment:\n",
        "            segments.append(current_segment[:])\n",
        "            current_segment = [line]\n",
        "            current_measures = line_measures\n",
        "        else:\n",
        "            current_segment.append(line)\n",
        "            current_measures += line_measures\n",
        "\n",
        "    # Agregar último segmento\n",
        "    if current_segment:\n",
        "        segments.append(current_segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def generate_voice_control_code(voice_id, segment_num, total_segments, measures, key, meter, piece_id):\n",
        "    \"\"\"Genera código de control específico para una voz con información de sincronización\"\"\"\n",
        "    control_parts = [\n",
        "        f\"PIECE:{piece_id}\",\n",
        "        f\"VOICE:{voice_id}\",\n",
        "        f\"MEASURES:{measures}\",\n",
        "        f\"KEY:{key}\",\n",
        "        f\"METER:{meter}\"\n",
        "    ]\n",
        "\n",
        "    # Agregar información de segmentación si aplica\n",
        "    if total_segments > 1:\n",
        "        control_parts.append(f\"SEGMENT:{segment_num}/{total_segments}\")\n",
        "\n",
        "    # Clasificación por complejidad\n",
        "    if measures <= 16:\n",
        "        control_parts.append(\"COMPLEXITY:SIMPLE\")\n",
        "    elif measures <= 32:\n",
        "        control_parts.append(\"COMPLEXITY:MEDIUM\")\n",
        "    else:\n",
        "        control_parts.append(\"COMPLEXITY:COMPLEX\")\n",
        "\n",
        "    return \" \".join(control_parts) + \"\\n\"\n",
        "\n",
        "def process_multi_voice_abc(content):\n",
        "    \"\"\"Procesa archivo ABC con múltiples voces y genera elementos separados pero sincronizados\"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Generar ID de pieza\n",
        "    piece_id = generate_piece_id(content)\n",
        "\n",
        "    # Limpiar metadata (solo una vez para toda la pieza)\n",
        "    clean_meta = clean_metadata(content)\n",
        "\n",
        "    # Extraer información básica\n",
        "    key = extract_key_signature(content)\n",
        "    meter = extract_time_signature(content)\n",
        "\n",
        "    # Extraer voces\n",
        "    voices = extract_voice_info(content)\n",
        "\n",
        "    if not voices:\n",
        "        # Si no hay voces explícitas, tratar como voz única\n",
        "        return process_single_voice_abc(content)\n",
        "\n",
        "    print(f\"Encontradas {len(voices)} voces: {list(voices.keys())}\")\n",
        "\n",
        "    # Dividir todas las voces en el mismo número de segmentos para mantener sincronización\n",
        "    all_voice_segments = {}\n",
        "    max_segments = 0\n",
        "\n",
        "    # Primero dividir cada voz y encontrar el máximo número de segmentos\n",
        "    for voice_num, voice_data in voices.items():\n",
        "        voice_content = voice_data['content']\n",
        "        if voice_content:\n",
        "            segments = split_voice_content(voice_content, max_measures=32)\n",
        "            all_voice_segments[voice_num] = segments\n",
        "            max_segments = max(max_segments, len(segments))\n",
        "\n",
        "    # Ahora generar elementos sincronizados\n",
        "    for segment_idx in range(max_segments):\n",
        "        segment_voices = []\n",
        "\n",
        "        # Recopilar todas las voces para este segmento\n",
        "        for voice_num, voice_data in voices.items():\n",
        "            if voice_num in all_voice_segments and segment_idx < len(all_voice_segments[voice_num]):\n",
        "                voice_id = voice_data['voice_id']\n",
        "                segment_content = all_voice_segments[voice_num][segment_idx]\n",
        "\n",
        "                if segment_content:\n",
        "                    segment_measures = count_measures_in_voice(segment_content)\n",
        "\n",
        "                    # Generar código de control\n",
        "                    control_code = generate_voice_control_code(\n",
        "                        voice_id, segment_idx+1, max_segments, segment_measures, key, meter, piece_id\n",
        "                    )\n",
        "\n",
        "                    # Construir notación ABC para este segmento\n",
        "                    # IMPORTANTE: Metadata solo en V1 del primer segmento\n",
        "                    abc_lines = []\n",
        "\n",
        "                    if voice_id == \"V1\" and segment_idx == 0:\n",
        "                        # Solo la primera voz del primer segmento lleva metadata completa\n",
        "                        abc_lines.append(clean_meta)\n",
        "                    else:\n",
        "                        # Otras voces/segmentos solo llevan el número X\n",
        "                        abc_lines.append(\"X:1\")\n",
        "\n",
        "                    abc_lines.append(f\"V:{voice_num}\")\n",
        "                    abc_lines.extend(segment_content)\n",
        "\n",
        "                    abc_notation = '\\n'.join(abc_lines)\n",
        "\n",
        "                    results.append({\n",
        "                        'control code': control_code,\n",
        "                        'abc notation': abc_notation\n",
        "                    })\n",
        "\n",
        "    return results\n",
        "\n",
        "def process_single_voice_abc(content):\n",
        "    \"\"\"Procesa archivo ABC de una sola voz\"\"\"\n",
        "    # Generar ID de pieza\n",
        "    piece_id = generate_piece_id(content)\n",
        "\n",
        "    # Limpiar metadata\n",
        "    clean_meta = clean_metadata(content)\n",
        "\n",
        "    # Extraer información básica\n",
        "    key = extract_key_signature(content)\n",
        "    meter = extract_time_signature(content)\n",
        "\n",
        "    # Separar metadata del contenido musical\n",
        "    lines = content.split('\\n')\n",
        "    musical_lines = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Solo líneas con contenido musical\n",
        "        if line.strip() and not (len(line) > 1 and line[0].isalpha() and line[1] == ':'):\n",
        "            if not line.startswith('%'):\n",
        "                musical_lines.append(line)\n",
        "\n",
        "    if not musical_lines:\n",
        "        return []\n",
        "\n",
        "    # Dividir en segmentos\n",
        "    segments = split_voice_content(musical_lines, max_measures=32)\n",
        "    results = []\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        if not segment:\n",
        "            continue\n",
        "\n",
        "        segment_measures = count_measures_in_voice(segment)\n",
        "\n",
        "        # Generar código de control\n",
        "        control_code = generate_voice_control_code(\n",
        "            'V1', i+1, len(segments), segment_measures, key, meter, piece_id\n",
        "        )\n",
        "\n",
        "        # Construir notación ABC\n",
        "        abc_lines = []\n",
        "\n",
        "        if i == 0:\n",
        "            # Solo el primer segmento lleva metadata completa\n",
        "            abc_lines.append(clean_meta)\n",
        "        else:\n",
        "            abc_lines.append(\"X:1\")\n",
        "\n",
        "        abc_lines.extend(segment)\n",
        "\n",
        "        abc_notation = '\\n'.join(abc_lines)\n",
        "\n",
        "        results.append({\n",
        "            'control code': control_code,\n",
        "            'abc notation': abc_notation\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def extract_key_signature(content):\n",
        "    \"\"\"Extrae la tonalidad de la pieza\"\"\"\n",
        "    lines = content.split('\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('K:'):\n",
        "            key = line[2:].strip()\n",
        "            key = re.sub(r'\\s+.*', '', key)\n",
        "            return key\n",
        "    return \"C\"\n",
        "\n",
        "def extract_time_signature(content):\n",
        "    \"\"\"Extrae el compás de la pieza\"\"\"\n",
        "    lines = content.split('\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('M:'):\n",
        "            meter = line[2:].strip()\n",
        "            return meter\n",
        "    return \"4/4\"\n",
        "\n",
        "def process_abc_file(filename):\n",
        "    \"\"\"Procesa un archivo ABC individual\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        if not content.strip():\n",
        "            return []\n",
        "\n",
        "        # Detectar si tiene múltiples voces\n",
        "        voice_pattern = re.findall(r'^V:\\d+', content, re.MULTILINE)\n",
        "        if voice_pattern:\n",
        "            return process_multi_voice_abc(content)\n",
        "        else:\n",
        "            return process_single_voice_abc(content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando {filename}: {e}\")\n",
        "        return []\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    data = []\n",
        "    filenames = []\n",
        "\n",
        "    # Buscar archivos ABC\n",
        "    possible_dirs = ['data_curation/abc_files']\n",
        "    abc_dir = None\n",
        "\n",
        "    for dir_path in possible_dirs:\n",
        "        if os.path.exists(dir_path):\n",
        "            abc_dir = dir_path\n",
        "            break\n",
        "\n",
        "    if abc_dir is None:\n",
        "        print(\"No se encontró directorio de archivos ABC\")\n",
        "        exit(1)\n",
        "\n",
        "    print(f\"Usando directorio: {abc_dir}\")\n",
        "\n",
        "    # Recopilar archivos\n",
        "    for dirpath, dirlist, filelist in os.walk(abc_dir):\n",
        "        for this_file in filelist:\n",
        "            if this_file.endswith(('.abc', '.txt')):\n",
        "                filename = os.path.join(dirpath, this_file)\n",
        "                filenames.append(filename)\n",
        "\n",
        "    print(f\"Archivos encontrados: {len(filenames)}\")\n",
        "\n",
        "    # Procesar todos los archivos\n",
        "    processed_files = 0\n",
        "    total_segments = 0\n",
        "\n",
        "    for filename in tqdm(filenames):\n",
        "        results = process_abc_file(filename)\n",
        "        if results:\n",
        "            data.extend(results)\n",
        "            processed_files += 1\n",
        "            total_segments += len(results)\n",
        "\n",
        "    print(f\"Archivos procesados: {processed_files}\")\n",
        "    print(f\"Segmentos generados: {total_segments}\")\n",
        "\n",
        "    # Estadísticas\n",
        "    voice_stats = {}\n",
        "    piece_stats = {}\n",
        "    complexity_stats = {}\n",
        "\n",
        "    for item in data:\n",
        "        # Estadísticas de voces\n",
        "        voice_match = re.search(r'VOICE:(\\w+)', item['control code'])\n",
        "        if voice_match:\n",
        "            voice = voice_match.group(1)\n",
        "            voice_stats[voice] = voice_stats.get(voice, 0) + 1\n",
        "\n",
        "        # Estadísticas de piezas\n",
        "        piece_match = re.search(r'PIECE:(\\w+)', item['control code'])\n",
        "        if piece_match:\n",
        "            piece = piece_match.group(1)\n",
        "            piece_stats[piece] = piece_stats.get(piece, 0) + 1\n",
        "\n",
        "        # Estadísticas de complejidad\n",
        "        complexity_match = re.search(r'COMPLEXITY:(\\w+)', item['control code'])\n",
        "        if complexity_match:\n",
        "            complexity = complexity_match.group(1)\n",
        "            complexity_stats[complexity] = complexity_stats.get(complexity, 0) + 1\n",
        "\n",
        "    print(f\"\\nSegmentos totales generados: {len(data)}\")\n",
        "    print(\"Distribución por voces:\", voice_stats)\n",
        "    print(f\"Número de piezas únicas: {len(piece_stats)}\")\n",
        "    print(\"Distribución por complejidad:\", complexity_stats)\n",
        "\n",
        "    # Guardar datos\n",
        "    output_file = 'data_curation/data_voice_synchronized.json'\n",
        "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Datos guardados en: {output_file}\")\n",
        "\n",
        "    # Mostrar ejemplos de sincronización\n",
        "    if len(data) > 0:\n",
        "        print(\"\\nEjemplo de sincronización - misma pieza, diferentes voces:\")\n",
        "        first_piece_id = None\n",
        "\n",
        "        for item in data:\n",
        "            piece_match = re.search(r'PIECE:(\\w+)', item['control code'])\n",
        "            if piece_match:\n",
        "                piece_id = piece_match.group(1)\n",
        "                if first_piece_id is None:\n",
        "                    first_piece_id = piece_id\n",
        "\n",
        "                if piece_id == first_piece_id:\n",
        "                    print(f\"\\nControl: {item['control code'].strip()}\")\n",
        "                    print(f\"ABC (primeros 150 chars): {item['abc notation'][:150]}\")\n",
        "\n",
        "                    # Mostrar solo primeros 3 elementos de la misma pieza\n",
        "                    voice_match = re.search(r'VOICE:(\\w+)', item['control code'])\n",
        "                    if voice_match and voice_match.group(1) == 'V3':\n",
        "                        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqmTE8SmRrd-",
        "outputId": "fa179c33-4538-4644-ace8-7f502191787b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando directorio: data_curation/abc_files\n",
            "Archivos encontrados: 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 21/70 [00:00<00:00, 201.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 8 voces: ['1', '2', '3', '4', '5', '6', '7', '8']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 7 voces: ['1', '2', '3', '4', '5', '6', '7']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 7 voces: ['1', '2', '3', '4', '5', '6', '7']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 176.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 8 voces: ['1', '2', '3', '4', '5', '6', '7', '8']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 7 voces: ['1', '2', '3', '4', '5', '6', '7']\n",
            "Encontradas 7 voces: ['1', '2', '3', '4', '5', '6', '7']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 6 voces: ['1', '2', '3', '4', '5', '6']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 7 voces: ['1', '2', '3', '4', '5', '6', '7']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Encontradas 8 voces: ['1', '2', '3', '4', '5', '6', '7', '8']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 4 voces: ['1', '2', '3', '4']\n",
            "Encontradas 5 voces: ['1', '2', '3', '4', '5']\n",
            "Archivos procesados: 70\n",
            "Segmentos generados: 3033\n",
            "\n",
            "Segmentos totales generados: 3033\n",
            "Distribución por voces: {'V1': 570, 'V2': 630, 'V3': 629, 'V4': 611, 'V5': 315, 'V6': 157, 'V7': 88, 'V8': 33}\n",
            "Número de piezas únicas: 19\n",
            "Distribución por complejidad: {'MEDIUM': 2877, 'SIMPLE': 156}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos guardados en: data_curation/data_voice_synchronized.json\n",
            "\n",
            "Ejemplo de sincronización - misma pieza, diferentes voces:\n",
            "\n",
            "Control: PIECE:64df3190 VOICE:V1 MEASURES:27 KEY:Eb METER:2/2 SEGMENT:1/9 COMPLEXITY:MEDIUM\n",
            "ABC (primeros 150 chars): X:1\n",
            "T:String Quartet\n",
            "C:Ludwig van Beethoven\n",
            "L:1/8\n",
            "M:2/2\n",
            "K:Eb\n",
            "V:1\n",
            "\"_sotto voce\"\"^Poco Adagio\" (e4 G3 A) | _d2 z4 z2 | (e4 G3 A) | _d8- | d6 =d2- | d4 (\n",
            "\n",
            "Control: PIECE:64df3190 VOICE:V2 MEASURES:32 KEY:Eb METER:2/2 SEGMENT:1/9 COMPLEXITY:MEDIUM\n",
            "ABC (primeros 150 chars): X:1\n",
            "V:2\n",
            "\"_sotto voce\" G4 E3 E | E2 z4 z2 | G4 E3 E | =E2 z2 b4- | b4 a4- | a4 (g2 fF) | (F4 A2 G2) | %7\n",
            " (G2 F) z B,2 B, z | C2 z4 z2 | z2\"_cresc.\" (F\n",
            "\n",
            "Control: PIECE:64df3190 VOICE:V3 MEASURES:31 KEY:Eb METER:2/2 SEGMENT:1/9 COMPLEXITY:MEDIUM\n",
            "ABC (primeros 150 chars): X:1\n",
            "V:3\n",
            "\"_sotto voce\" B,8 (B,6 A,2) | G,4 z8 z4 | B,8 (B,6 A,2) | B,4 z8 =E4- | E8 F8- | (F4 _c4 B4 =C4) | %6\n",
            " (A,8 D,6 _E,2) | (=E,4 F,4 D,4 _E,4) | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean json data\n"
      ],
      "metadata": {
        "id": "R9KYYfeWST-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "def clean_abc_notation(abc_text):\n",
        "    \"\"\"Limpia notación ABC para facilitar el aprendizaje del modelo\"\"\"\n",
        "\n",
        "    # Remover indicaciones interpretativas complejas pero mantener dinámicas básicas\n",
        "    # Mantener: !p!, !f!, !mp!, !mf!\n",
        "    # Remover: indicaciones de texto complejas\n",
        "    abc_text = re.sub(r'\"[^\"]*\"(?![fp]!)', '', abc_text)  # Remover texto entre comillas excepto dinámicas\n",
        "\n",
        "    # Simplificar ornamentos complejos\n",
        "    abc_text = re.sub(r'\\{[^}]*\\}', '', abc_text)  # Remover grace notes complejas\n",
        "\n",
        "    # Limpiar comentarios de compás\n",
        "    abc_text = re.sub(r'\\s*%\\d+', '', abc_text)  # Remover números de compás\n",
        "\n",
        "    # Normalizar espacios\n",
        "    abc_text = re.sub(r'\\s+', ' ', abc_text)\n",
        "    abc_text = re.sub(r'\\s*\\|\\s*', '|', abc_text)  # Normalizar barras\n",
        "\n",
        "    return abc_text.strip()\n",
        "\n",
        "def validate_synchronization(data):\n",
        "    \"\"\"Valida que las voces estén sincronizadas correctamente\"\"\"\n",
        "    pieces = {}\n",
        "\n",
        "    # Agrupar por pieza y segmento\n",
        "    for item in data:\n",
        "        piece_match = re.search(r'PIECE:(\\w+)', item['control code'])\n",
        "        segment_match = re.search(r'SEGMENT:(\\d+)/(\\d+)', item['control code'])\n",
        "\n",
        "        if piece_match and segment_match:\n",
        "            piece_id = piece_match.group(1)\n",
        "            segment_num = segment_match.group(1)\n",
        "            total_segments = segment_match.group(2)\n",
        "\n",
        "            key = f\"{piece_id}_SEG{segment_num}\"\n",
        "\n",
        "            if key not in pieces:\n",
        "                pieces[key] = []\n",
        "\n",
        "            pieces[key].append(item)\n",
        "\n",
        "    # Validar cada grupo\n",
        "    issues = []\n",
        "    for key, items in pieces.items():\n",
        "        if len(items) > 1:\n",
        "            # Extraer medidas de cada voz\n",
        "            measures = []\n",
        "            for item in items:\n",
        "                measure_match = re.search(r'MEASURES:(\\d+)', item['control code'])\n",
        "                if measure_match:\n",
        "                    measures.append(int(measure_match.group(1)))\n",
        "\n",
        "            # Verificar si están sincronizadas (diferencia máxima de 2 compases)\n",
        "            if measures and (max(measures) - min(measures)) > 2:\n",
        "                issues.append(f\"{key}: medidas desincronizadas {measures}\")\n",
        "\n",
        "    return issues\n",
        "\n",
        "def filter_training_ready_data(input_file, output_file):\n",
        "    \"\"\"Filtra y limpia datos para entrenamiento\"\"\"\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Datos originales: {len(data)} elementos\")\n",
        "\n",
        "    # Validar sincronización\n",
        "    sync_issues = validate_synchronization(data)\n",
        "    if sync_issues:\n",
        "        print(f\"Encontrados {len(sync_issues)} problemas de sincronización\")\n",
        "        for issue in sync_issues[:5]:  # Mostrar primeros 5\n",
        "            print(f\"  {issue}\")\n",
        "\n",
        "    # Limpiar notación ABC\n",
        "    cleaned_data = []\n",
        "    for item in data:\n",
        "        cleaned_item = item.copy()\n",
        "        cleaned_item['abc notation'] = clean_abc_notation(item['abc notation'])\n",
        "\n",
        "        # Filtrar elementos muy cortos o muy largos\n",
        "        abc_length = len(cleaned_item['abc notation'])\n",
        "        if 50 <= abc_length <= 2000:  # Rango razonable\n",
        "            cleaned_data.append(cleaned_item)\n",
        "\n",
        "    print(f\"Datos después de limpieza: {len(cleaned_data)} elementos\")\n",
        "\n",
        "    # Guardar datos limpios\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Estadísticas finales\n",
        "    voice_stats = {}\n",
        "    for item in cleaned_data:\n",
        "        voice_match = re.search(r'VOICE:(\\w+)', item['control code'])\n",
        "        if voice_match:\n",
        "            voice = voice_match.group(1)\n",
        "            voice_stats[voice] = voice_stats.get(voice, 0) + 1\n",
        "\n",
        "    print(f\"Distribución final por voces: {voice_stats}\")\n",
        "    print(f\"Datos listos para entrenamiento guardados en: {output_file}\")\n",
        "\n",
        "    # Mostrar ejemplo limpio\n",
        "    if cleaned_data:\n",
        "        print(f\"\\nEjemplo de dato limpio:\")\n",
        "        print(f\"Control: {cleaned_data[0]['control code'].strip()}\")\n",
        "        print(f\"ABC (primeros 200 chars): {cleaned_data[0]['abc notation'][:200]}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = 'data_curation/data_voice_synchronized.json'\n",
        "    output_file = 'data_curation/data_training_ready.json'\n",
        "\n",
        "    filter_training_ready_data(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QaDpOmzSTow",
        "outputId": "7939f164-9da8-4ace-f6da-a9636745da98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos originales: 3033 elementos\n",
            "Encontrados 218 problemas de sincronización\n",
            "  64df3190_SEG1: medidas desincronizadas [27, 32, 31, 28, 29, 27, 29, 19, 30, 29, 26, 31, 30, 30, 32, 29, 30]\n",
            "  64df3190_SEG2: medidas desincronizadas [30, 30, 31, 32, 30, 27, 30, 19, 29, 31, 31, 31, 30, 28, 27, 28, 31]\n",
            "  64df3190_SEG3: medidas desincronizadas [31, 31, 32, 30, 30, 29, 32, 19, 29, 22, 22, 22, 28, 30, 27, 31, 30]\n",
            "  64df3190_SEG4: medidas desincronizadas [28, 31, 29, 32, 29, 31, 29, 19, 32, 32, 17, 29, 29, 32, 28, 30, 30]\n",
            "  64df3190_SEG5: medidas desincronizadas [29, 32, 29, 30, 29, 27, 30, 19, 28, 23, 30, 28, 32, 31, 22, 30, 32]\n",
            "Datos después de limpieza: 3023 elementos\n",
            "Distribución final por voces: {'V1': 568, 'V2': 625, 'V3': 628, 'V4': 610, 'V5': 315, 'V6': 157, 'V7': 88, 'V8': 32}\n",
            "Datos listos para entrenamiento guardados en: data_curation/data_training_ready.json\n",
            "\n",
            "Ejemplo de dato limpio:\n",
            "Control: PIECE:64df3190 VOICE:V1 MEASURES:27 KEY:Eb METER:2/2 SEGMENT:1/9 COMPLEXITY:MEDIUM\n",
            "ABC (primeros 200 chars): X:1 T:String Quartet C:Ludwig van Beethoven L:1/8 M:2/2 K:Eb V:1 (e4 G3 A)|_d2 z4 z2|(e4 G3 A)|_d8-|d6 =d2-|d4 (e2 cf|e2 d2 c2 B2)|(B2 A) z (A2 G) z|(G2- G/F/=E/F/ E/F/G/F/) (=e/f/g/f/)|a2 (_C2 B,2 B3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from utils import *\n",
        "from config import *\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Config, get_scheduler\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "random.seed(42)\n",
        "# Fix: Asegurar que batch_size sea al menos 1\n",
        "batch_size = max(1, torch.cuda.device_count())\n",
        "patchilizer = Patchilizer()\n",
        "\n",
        "patch_config = GPT2Config(num_hidden_layers=PATCH_NUM_LAYERS,\n",
        "                    max_length=PATCH_LENGTH,\n",
        "                    max_position_embeddings=PATCH_LENGTH,\n",
        "                    vocab_size=1)\n",
        "char_config = GPT2Config(num_hidden_layers=CHAR_NUM_LAYERS,\n",
        "                    max_length=PATCH_SIZE,\n",
        "                    max_position_embeddings=PATCH_SIZE,\n",
        "                    vocab_size=128)\n",
        "model = TunesFormer(patch_config, char_config, share_weights=SHARE_WEIGHTS)\n",
        "\n",
        "# print parameter number\n",
        "print(\"Parameter Number: \"+str(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "scaler = GradScaler()\n",
        "is_autocast = True\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    input_patches = []\n",
        "\n",
        "    for input_patch in batch:\n",
        "        input_patches.append(input_patch.reshape(-1))\n",
        "\n",
        "    input_patches = torch.nn.utils.rnn.pad_sequence(input_patches, batch_first=True, padding_value=0)\n",
        "\n",
        "    return input_patches.to(device)\n",
        "\n",
        "def split_data(data, eval_ratio=0.1):\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data)*eval_ratio)\n",
        "    eval_set = data[:split_idx]\n",
        "    train_set = data[split_idx:]\n",
        "    return train_set, eval_set\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, items):\n",
        "        self.texts = []\n",
        "\n",
        "        for item in tqdm(items):\n",
        "            text = item['control code']+\"\\n\".join(item['abc notation'].split('\\n')[1:])\n",
        "            input_patch =  patchilizer.encode(text, add_special_patches=True)\n",
        "            input_patch = torch.tensor(input_patch)\n",
        "            if torch.sum(input_patch)!=0:\n",
        "                self.texts.append(input_patch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "# call model with a batch of input\n",
        "def process_one_batch(batch):\n",
        "    input_patches = batch\n",
        "\n",
        "    loss = model(input_patches).loss\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "# do one epoch for training\n",
        "def train_epoch():\n",
        "    tqdm_train_set = tqdm(train_set)\n",
        "    total_train_loss = 0\n",
        "    iter_idx = 1\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm_train_set:\n",
        "        try:\n",
        "            if is_autocast:\n",
        "                with autocast():\n",
        "                    loss = process_one_batch(batch)\n",
        "                if loss==None or torch.isnan(loss).item():\n",
        "                    continue\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss = process_one_batch(batch)\n",
        "                if loss==None or torch.isnan(loss).item():\n",
        "                    continue\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        except RuntimeError as exception:\n",
        "            if \"memory\" in str(exception):\n",
        "                print(str(exception))\n",
        "                if hasattr(torch.cuda, 'empty_cache'):\n",
        "                    torch.cuda.empty_cache()\n",
        "                continue\n",
        "            else:\n",
        "                raise exception\n",
        "        lr_scheduler.step()\n",
        "        model.zero_grad(set_to_none=True)\n",
        "        total_train_loss += loss.item()\n",
        "        tqdm_train_set.set_postfix({'train_loss': total_train_loss / iter_idx})\n",
        "        iter_idx += 1\n",
        "\n",
        "    return total_train_loss / (iter_idx-1)\n",
        "\n",
        "# do one epoch for eval\n",
        "def eval_epoch():\n",
        "    tqdm_eval_set = tqdm(eval_set)\n",
        "    total_eval_loss = 0\n",
        "    iter_idx = 1\n",
        "    model.eval()\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm_eval_set:\n",
        "        with torch.no_grad():\n",
        "            loss = process_one_batch(batch)\n",
        "            if loss==None or torch.isnan(loss).item():\n",
        "                continue\n",
        "            total_eval_loss += loss.item()\n",
        "        tqdm_eval_set.set_postfix({'eval_loss': total_eval_loss / iter_idx})\n",
        "        iter_idx += 1\n",
        "\n",
        "    return total_eval_loss / (iter_idx-1)\n",
        "\n",
        "NUM_EPOCHS = 20  # Aumentar a 100 épocas\n",
        "\n",
        "# train and eval\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # load data\n",
        "    with open('data_curation/data_training_ready.json') as f:\n",
        "        print(\"Loading Data...\")\n",
        "        data = json.load(f)\n",
        "        train_set, eval_set = split_data(data)\n",
        "        data = []\n",
        "\n",
        "    train_set = DataLoader(MyDataset(train_set), batch_size=batch_size, collate_fn=collate_batch, shuffle=True)\n",
        "    eval_set = DataLoader(MyDataset(eval_set), batch_size=batch_size, collate_fn=collate_batch, shuffle=True)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=\"cosine\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=NUM_EPOCHS * len(train_set) / 10,\n",
        "        num_training_steps=NUM_EPOCHS * len(train_set),\n",
        "    )\n",
        "    if LOAD_FROM_CHECKPOINT and os.path.exists('weights3.pth'):\n",
        "        checkpoint = torch.load('weights3.pth')\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model.module.load_state_dict(checkpoint['model'])\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint['model'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        lr_scheduler.load_state_dict(checkpoint['lr_sched'])\n",
        "        pre_epoch = checkpoint['epoch']\n",
        "        best_epoch = checkpoint['best_epoch']\n",
        "        min_eval_loss = checkpoint['min_eval_loss']\n",
        "        print(\"Successfully Loaded Checkpoint from Epoch %d\" % pre_epoch)\n",
        "\n",
        "    else:\n",
        "        pre_epoch = 0\n",
        "        best_epoch = 0\n",
        "        min_eval_loss = 100\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(1, NUM_EPOCHS+1-pre_epoch):\n",
        "        epoch += pre_epoch\n",
        "        print('-' * 21 + \"Epoch \" + str(epoch) + '-' * 21)\n",
        "        train_loss = train_epoch()\n",
        "        eval_loss = eval_epoch()\n",
        "        with open('logs.txt','a') as f:\n",
        "            f.write(\"Epoch \" + str(epoch) + \"\\ntrain_loss: \" + str(train_loss) + \"\\neval_loss: \" +str(eval_loss) + \"\\ntime: \" + time.asctime(time.localtime(time.time())) + \"\\n\\n\")\n",
        "        if eval_loss < min_eval_loss:\n",
        "            best_epoch = epoch\n",
        "            min_eval_loss = eval_loss\n",
        "            if torch.cuda.device_count() > 1:\n",
        "                checkpoint = {\n",
        "                'model': model.module.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_sched': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'best_epoch': best_epoch,\n",
        "                'min_eval_loss': min_eval_loss}\n",
        "            else:\n",
        "                checkpoint = {\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_sched': lr_scheduler.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'best_epoch': best_epoch,\n",
        "                'min_eval_loss': min_eval_loss}\n",
        "            torch.save(checkpoint, 'weights3.pth')\n",
        "\n",
        "    print(\"Best Eval Epoch : \"+str(best_epoch))\n",
        "    print(\"Min Eval Loss : \"+str(min_eval_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "X6eI-MQpYovH",
        "outputId": "f71330d1-43d4-4447-a9ef-3fd55c7c89f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter Number: 88425984\n",
            "Loading Data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-95c0fed4c85f>:39: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "100%|██████████| 2721/2721 [00:00<00:00, 20592.11it/s]\n",
            "100%|██████████| 302/302 [00:00<00:00, 20070.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 1---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/2721 [00:00<?, ?it/s]<ipython-input-5-95c0fed4c85f>:95: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "100%|██████████| 2721/2721 [03:41<00:00, 12.29it/s, train_loss=0.106]\n",
            "100%|██████████| 302/302 [00:04<00:00, 60.61it/s, eval_loss=0.0816]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 2---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2721/2721 [03:37<00:00, 12.52it/s, train_loss=0.0776]\n",
            "100%|██████████| 302/302 [00:04<00:00, 73.70it/s, eval_loss=0.0766]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 3---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2721/2721 [03:43<00:00, 12.19it/s, train_loss=0.0757]\n",
            "100%|██████████| 302/302 [00:04<00:00, 72.97it/s, eval_loss=0.0772]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 4---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2721/2721 [03:32<00:00, 12.81it/s, train_loss=0.0749]\n",
            "100%|██████████| 302/302 [00:04<00:00, 65.00it/s, eval_loss=0.0756]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 5---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2721/2721 [03:43<00:00, 12.17it/s, train_loss=0.073]\n",
            "100%|██████████| 302/302 [00:04<00:00, 74.25it/s, eval_loss=0.0732]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------Epoch 6---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▋         | 174/2721 [00:14<03:39, 11.61it/s, train_loss=0.0758]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-95c0fed4c85f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpre_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m21\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Epoch \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0meval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-95c0fed4c85f>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_autocast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-95c0fed4c85f>\u001b[0m in \u001b[0;36mprocess_one_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0minput_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_patches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/tunesformer-main/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, patches, patch_sampling_batch_size)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mencoded_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_level_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"last_hidden_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_level_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_sampling_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/tunesformer-main/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, patches)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCharLevelDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import sys\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "# Definir rutas específicas para tu entorno\n",
        "project_root = '/content/drive/MyDrive/tunesformer-main'\n",
        "weights_path = f'{project_root}/weights3.pth'\n",
        "output_dir = f'{project_root}/output_tunes'\n",
        "prompt_path = f'{project_root}/prompt.txt'\n",
        "\n",
        "# Asegurarse de que project_root está en sys.path\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# Importar módulos después de configurar sys.path\n",
        "try:\n",
        "    from utils import Patchilizer, TunesFormer\n",
        "    from config import *\n",
        "    from transformers import GPT2Config\n",
        "    print(\"Módulos importados correctamente\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error al importar módulos: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Definir las funciones de muestreo directamente para evitar problemas\n",
        "def custom_top_p_sampling(probs, p=0.9):\n",
        "    \"\"\"\n",
        "    Implementación de top-p sampling (nucleus sampling)\n",
        "\n",
        "    Args:\n",
        "        probs: Probabilidades de cada token\n",
        "        p: Valor de probabilidad acumulativa para filtrar tokens (0.0-1.0)\n",
        "\n",
        "    Returns:\n",
        "        Distribución de probabilidad filtrada\n",
        "    \"\"\"\n",
        "    # Ordena las probabilidades de mayor a menor\n",
        "    sorted_indices = np.argsort(-probs)\n",
        "    sorted_probs = probs[sorted_indices]\n",
        "    cumulative_probs = np.cumsum(sorted_probs)\n",
        "\n",
        "    # Eliminar tokens con probabilidad acumulada > p\n",
        "    sorted_indices_to_remove = cumulative_probs > p\n",
        "\n",
        "    # Desplazar la máscara para mantener al menos un token\n",
        "    if len(sorted_indices_to_remove) > 1:\n",
        "        sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1]\n",
        "    sorted_indices_to_remove[0] = False\n",
        "\n",
        "    # Aplicar la máscara\n",
        "    indices_to_remove = np.zeros_like(probs, dtype=bool)\n",
        "    for i, should_remove in enumerate(sorted_indices_to_remove):\n",
        "        if should_remove:\n",
        "            indices_to_remove[sorted_indices[i]] = True\n",
        "\n",
        "    # Filtrar y renormalizar\n",
        "    filtered_probs = np.copy(probs)\n",
        "    filtered_probs[indices_to_remove] = 0\n",
        "    sum_p = np.sum(filtered_probs)\n",
        "    if sum_p > 0:\n",
        "        filtered_probs = filtered_probs / sum_p\n",
        "    else:\n",
        "        # Si todas las probabilidades son cero, usar distribución uniforme\n",
        "        filtered_probs = np.ones_like(probs) / len(probs)\n",
        "\n",
        "    return filtered_probs\n",
        "\n",
        "def custom_top_k_sampling(probs, k=50):\n",
        "    \"\"\"\n",
        "    Implementación de top-k sampling\n",
        "\n",
        "    Args:\n",
        "        probs: Probabilidades de cada token\n",
        "        k: Número de tokens con mayor probabilidad a mantener\n",
        "\n",
        "    Returns:\n",
        "        Distribución de probabilidad filtrada\n",
        "    \"\"\"\n",
        "    # Ajusta k si es mayor que el número de tokens\n",
        "    k = min(k, len(probs))\n",
        "\n",
        "    # Obtiene los k tokens con mayor probabilidad\n",
        "    top_k_indices = np.argsort(-probs)[:k]\n",
        "    top_k_probs = probs[top_k_indices]\n",
        "\n",
        "    # Crea una nueva distribución\n",
        "    filtered_probs = np.zeros_like(probs)\n",
        "    filtered_probs[top_k_indices] = top_k_probs\n",
        "\n",
        "    # Renormaliza\n",
        "    filtered_probs = filtered_probs / np.sum(filtered_probs)\n",
        "\n",
        "    return filtered_probs\n",
        "\n",
        "def custom_temperature_sampling(probs, temperature=1.0, seed=None):\n",
        "    \"\"\"\n",
        "    Implementación de temperature sampling\n",
        "\n",
        "    Args:\n",
        "        probs: Probabilidades de cada token\n",
        "        temperature: Factor de temperatura (>1 más aleatorio, <1 más determinista)\n",
        "        seed: Semilla para reproducibilidad\n",
        "\n",
        "    Returns:\n",
        "        Índice del token seleccionado\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    if temperature == 0:\n",
        "        # Si temperatura es cero, retornar el token con mayor probabilidad\n",
        "        return np.argmax(probs)\n",
        "\n",
        "    # Aplicar temperatura\n",
        "    if temperature != 1.0:\n",
        "        probs = np.power(probs, 1.0 / max(1e-8, temperature))\n",
        "        # Renormalizar\n",
        "        probs = probs / np.sum(probs)\n",
        "\n",
        "    # Seleccionar un token basado en la distribución\n",
        "    return np.random.choice(len(probs), p=probs)\n",
        "\n",
        "def free_memory():\n",
        "    \"\"\"Liberar memoria GPU y RAM\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "def ensure_dirs_exist(paths):\n",
        "    \"\"\"Asegura que los directorios existan\"\"\"\n",
        "    for path in paths:\n",
        "        # Si es un archivo, obtener el directorio\n",
        "        if '.' in os.path.basename(path):\n",
        "            directory = os.path.dirname(path)\n",
        "        else:\n",
        "            directory = path\n",
        "\n",
        "        if directory and not os.path.exists(directory):\n",
        "            print(f\"Creando directorio: {directory}\")\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Modificación de la clase TunesFormer para usar nuestras funciones personalizadas\n",
        "class CustomTunesFormer(TunesFormer):\n",
        "    def generate(self, patches, tokens=None, top_p=1, top_k=0, temperature=1, seed=None):\n",
        "        \"\"\"\n",
        "        Versión personalizada del método generate que usa nuestras funciones de muestreo\n",
        "        \"\"\"\n",
        "        patches = patches.reshape(len(patches), -1, PATCH_SIZE)\n",
        "        encoded_patches = self.patch_level_decoder(patches)[\"last_hidden_state\"]\n",
        "        if tokens is None:\n",
        "            tokens = torch.tensor([self.bos_token_id], device=self.device)\n",
        "        generated_patch = []\n",
        "\n",
        "        if seed is not None:\n",
        "            import random\n",
        "            random.seed(seed)\n",
        "\n",
        "        while True:\n",
        "            if seed is not None:\n",
        "                n_seed = random.randint(0, 1000000)\n",
        "                random.seed(n_seed)\n",
        "            else:\n",
        "                n_seed = None\n",
        "\n",
        "            # Obtener probabilidades\n",
        "            prob = self.char_level_decoder.generate(encoded_patches[0][-1], tokens).cpu().detach().numpy()\n",
        "\n",
        "            # Aplicar muestreos personalizados\n",
        "            prob = custom_top_p_sampling(prob, p=top_p)\n",
        "            prob = custom_top_k_sampling(prob, k=top_k if top_k > 0 else len(prob))\n",
        "            token = custom_temperature_sampling(prob, temperature=temperature, seed=n_seed)\n",
        "\n",
        "            generated_patch.append(token)\n",
        "            if token == self.eos_token_id or len(tokens) >= PATCH_SIZE - 1:\n",
        "                break\n",
        "            else:\n",
        "                tokens = torch.cat((tokens, torch.tensor([token], device=self.device)), dim=0)\n",
        "\n",
        "        return generated_patch, n_seed\n",
        "\n",
        "def generate_abc(num_tunes=3, max_patch=128, top_p=0.8, top_k=8,\n",
        "                 temperature=1.2, seed=None, show_control_code=True,\n",
        "                 weights=weights_path, prompt=prompt_path, output=output_dir):\n",
        "    \"\"\"Genera melodías ABC utilizando el modelo TunesFormer\"\"\"\n",
        "\n",
        "    # Asegurar que los directorios existan\n",
        "    ensure_dirs_exist([weights, output, prompt])\n",
        "\n",
        "    # Verificar disponibilidad de GPU\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Usando GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Usando CPU (el proceso será más lento)\")\n",
        "\n",
        "    # Inicializar modelo y componentes\n",
        "    try:\n",
        "        patchilizer = Patchilizer()\n",
        "\n",
        "        # Configuración del modelo\n",
        "        patch_config = GPT2Config(num_hidden_layers=PATCH_NUM_LAYERS,\n",
        "                            max_length=PATCH_LENGTH,\n",
        "                            max_position_embeddings=PATCH_LENGTH,\n",
        "                            vocab_size=1)\n",
        "        char_config = GPT2Config(num_hidden_layers=CHAR_NUM_LAYERS,\n",
        "                            max_length=PATCH_SIZE,\n",
        "                            max_position_embeddings=PATCH_SIZE,\n",
        "                            vocab_size=128)\n",
        "\n",
        "        # Usar nuestra clase personalizada en lugar de TunesFormer\n",
        "        model = CustomTunesFormer(patch_config, char_config, share_weights=SHARE_WEIGHTS)\n",
        "\n",
        "        print(f\"Modelo inicializado con {sum(p.numel() for p in model.parameters() if p.requires_grad)} parámetros\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al inicializar el modelo: {e}\")\n",
        "        return\n",
        "\n",
        "    # Cargar pesos del modelo\n",
        "    if os.path.exists(weights):\n",
        "        print(f\"Cargando pesos desde '{weights}'...\")\n",
        "        try:\n",
        "            # Algunas veces hay problemas de memoria, intentar liberar primero\n",
        "            free_memory()\n",
        "\n",
        "            # Cargar checkpoint con map_location para flexibilidad GPU/CPU\n",
        "            checkpoint = torch.load(weights, map_location=device)\n",
        "\n",
        "            # Diferentes formas de cargar según la estructura del checkpoint\n",
        "            if 'model' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['model'])\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint)\n",
        "\n",
        "            print(\"Pesos cargados exitosamente\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error al cargar pesos: {e}\")\n",
        "            print(\"Intentando descargar pesos desde Hugging Face...\")\n",
        "            try:\n",
        "                url = 'https://huggingface.co/sander-wood/tunesformer/resolve/main/weights.pth'\n",
        "                response = requests.get(url, stream=True)\n",
        "\n",
        "                total_size = int(response.headers.get('content-length', 0))\n",
        "                chunk_size = 1024\n",
        "\n",
        "                with open(weights, 'wb') as file, tqdm(\n",
        "                    desc=os.path.basename(weights),\n",
        "                    total=total_size,\n",
        "                    unit='B',\n",
        "                    unit_scale=True,\n",
        "                    unit_divisor=1024,\n",
        "                ) as bar:\n",
        "                    for data in response.iter_content(chunk_size=chunk_size):\n",
        "                        size = file.write(data)\n",
        "                        bar.update(size)\n",
        "\n",
        "                # Intentar cargar de nuevo\n",
        "                checkpoint = torch.load(weights, map_location=device)\n",
        "                if 'model' in checkpoint:\n",
        "                    model.load_state_dict(checkpoint['model'])\n",
        "                else:\n",
        "                    model.load_state_dict(checkpoint)\n",
        "                print(\"Pesos descargados y cargados exitosamente\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error al descargar/cargar pesos: {e}\")\n",
        "                return\n",
        "    else:\n",
        "        print(f\"No se encontraron pesos en '{weights}'. Descargando...\")\n",
        "        try:\n",
        "            url = 'https://huggingface.co/sander-wood/tunesformer/resolve/main/weights.pth'\n",
        "            response = requests.get(url, stream=True)\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            chunk_size = 1024\n",
        "\n",
        "            with open(weights, 'wb') as file, tqdm(\n",
        "                desc=os.path.basename(weights),\n",
        "                total=total_size,\n",
        "                unit='B',\n",
        "                unit_scale=True,\n",
        "                unit_divisor=1024,\n",
        "            ) as bar:\n",
        "                for data in response.iter_content(chunk_size=chunk_size):\n",
        "                    size = file.write(data)\n",
        "                    bar.update(size)\n",
        "\n",
        "            # Cargar los pesos descargados\n",
        "            checkpoint = torch.load(weights, map_location=device)\n",
        "            if 'model' in checkpoint:\n",
        "                model.load_state_dict(checkpoint['model'])\n",
        "            else:\n",
        "                model.load_state_dict(checkpoint)\n",
        "            print(\"Pesos descargados y cargados exitosamente\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return\n",
        "\n",
        "    # Mover modelo al dispositivo apropiado y configurar para evaluación\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Cargar prompt\n",
        "    try:\n",
        "        if os.path.exists(prompt):\n",
        "            with open(prompt, 'r', encoding='utf-8') as f:\n",
        "                prompt_text = f.read()\n",
        "                print(f\"Prompt cargado desde '{prompt}'\")\n",
        "        else:\n",
        "            # Si no existe el archivo, usar un prompt por defecto\n",
        "            prompt_text = \"\"\"M:3/4\n",
        "L:1/8\n",
        "K:C\n",
        "\"\"\"\n",
        "            # Guardar el prompt por defecto para futuros usos\n",
        "            with open(prompt, 'w', encoding='utf-8') as f:\n",
        "                f.write(prompt_text)\n",
        "            print(f\"Archivo de prompt no encontrado. Se creó un prompt por defecto en '{prompt}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar el prompt: {e}\")\n",
        "        # Usar prompt mínimo\n",
        "        prompt_text = \"\"\"M:3/4\n",
        "L:1/8\n",
        "K:C\n",
        "\"\"\"\n",
        "        print(\"Se usará un prompt mínimo por defecto\")\n",
        "\n",
        "    # Inicializar variable para almacenar todas las melodías\n",
        "    tunes = \"\"\n",
        "\n",
        "    # Mostrar parámetros de generación\n",
        "    print(\"\\n\" + \" PARÁMETROS DE GENERACIÓN \".center(60, \"#\") + '\\n')\n",
        "    params = {\n",
        "        'num_tunes': num_tunes,\n",
        "        'max_patch': max_patch,\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'temperature': temperature,\n",
        "        'seed': seed,\n",
        "        'show_control_code': show_control_code\n",
        "    }\n",
        "    for key, value in params.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(\"\\n\" + \" MELODÍAS GENERADAS \".center(60, \"#\"))\n",
        "\n",
        "    # Tiempo de inicio para medir la generación\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Generar cada melodía\n",
        "        for i in range(num_tunes):\n",
        "            print(f\"\\n--- Melodía {i+1}/{num_tunes} ---\\n\")\n",
        "\n",
        "            # Preparar la melodía con el número y el prompt\n",
        "            tune = f\"X:{i+1}\\n{prompt_text}\"\n",
        "            lines = re.split(r'(\\n)', tune)\n",
        "            tune_output = \"\"\n",
        "            skip = False\n",
        "\n",
        "            # Procesar y mostrar líneas iniciales\n",
        "            for line in lines:\n",
        "                if show_control_code or line[:2] not in [\"S:\", \"B:\", \"E:\"]:\n",
        "                    if not skip:\n",
        "                        print(line, end=\"\")\n",
        "                        tune_output += line\n",
        "                    skip = False\n",
        "                else:\n",
        "                    skip = True\n",
        "\n",
        "            # Preparar entrada para el modelo\n",
        "            try:\n",
        "                input_patches = torch.tensor([patchilizer.encode(prompt_text, add_special_patches=True)[:-1]], device=device)\n",
        "\n",
        "                if tune_output == \"\":\n",
        "                    tokens = None\n",
        "                else:\n",
        "                    prefix = patchilizer.decode(input_patches[0])\n",
        "                    remaining_tokens = prompt_text[len(prefix):]\n",
        "                    tokens = torch.tensor([patchilizer.bos_token_id] + [ord(c) for c in remaining_tokens], device=device)\n",
        "\n",
        "                # Generar la melodía secuencialmente hasta alcanzar max_patch o EOS\n",
        "                while input_patches.shape[1] < max_patch:\n",
        "                    # Liberar memoria periódicamente\n",
        "                    if input_patches.shape[1] % 20 == 0:\n",
        "                        free_memory()\n",
        "\n",
        "                    # Generar siguiente patch\n",
        "                    predicted_patch, seed = model.generate(\n",
        "                        input_patches,\n",
        "                        tokens,\n",
        "                        top_p=top_p,\n",
        "                        top_k=top_k,\n",
        "                        temperature=temperature,\n",
        "                        seed=seed\n",
        "                    )\n",
        "                    tokens = None\n",
        "\n",
        "                    # Si no es fin de secuencia, procesar el nuevo patch\n",
        "                    if predicted_patch[0] != patchilizer.eos_token_id:\n",
        "                        next_bar = patchilizer.decode([predicted_patch])\n",
        "\n",
        "                        # Mostrar y agregar a la salida si no es código de control o si se solicita mostrarlos\n",
        "                        if show_control_code or next_bar[:2] not in [\"S:\", \"B:\", \"E:\"]:\n",
        "                            print(next_bar, end=\"\")\n",
        "                            tune_output += next_bar\n",
        "\n",
        "                        # Si el patch generado está vacío, terminar\n",
        "                        if next_bar == \"\":\n",
        "                            break\n",
        "\n",
        "                        # Preparar para la siguiente iteración\n",
        "                        next_bar = remaining_tokens + next_bar\n",
        "                        remaining_tokens = \"\"\n",
        "                        predicted_patch = torch.tensor(patchilizer.bar2patch(next_bar), device=device).unsqueeze(0)\n",
        "\n",
        "                        # Concatenar a las entradas\n",
        "                        input_patches = torch.cat([input_patches, predicted_patch.unsqueeze(0)], dim=1)\n",
        "                    else:\n",
        "                        # Fin de secuencia encontrado\n",
        "                        break\n",
        "\n",
        "                # Añadir la melodía completa a la colección\n",
        "                tunes += tune_output + \"\\n\\n\"\n",
        "                print(\"\\n\")\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                # Manejo específico para errores de memoria\n",
        "                if \"memory\" in str(e).lower():\n",
        "                    print(f\"Error de memoria al generar melodía {i+1}: {e}\")\n",
        "                    print(\"Intentando liberar memoria y continuar con la siguiente melodía...\")\n",
        "                    free_memory()\n",
        "                else:\n",
        "                    print(f\"Error al generar melodía {i+1}: {e}\")\n",
        "\n",
        "                # Añadir lo que se haya generado hasta ahora\n",
        "                tunes += tune_output + \"\\n\\n\"\n",
        "                print(\"\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error durante la generación: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Mostrar tiempo total de generación\n",
        "    generation_time = time.time() - start_time\n",
        "    print(f\"Tiempo de generación: {generation_time:.2f} segundos\")\n",
        "\n",
        "    # Crear timestamp para el nombre de archivo\n",
        "    timestamp = time.strftime(\"%a_%d_%b_%Y_%H_%M_%S\", time.localtime())\n",
        "\n",
        "    # Asegurar que el directorio de salida existe\n",
        "    os.makedirs(output, exist_ok=True)\n",
        "\n",
        "    # Guardar las melodías generadas\n",
        "    output_file = os.path.join(output, f'{timestamp}.abc')\n",
        "    try:\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(tunes)\n",
        "        print(f\"Melodías guardadas en: {output_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al guardar el archivo: {e}\")\n",
        "        # Intentar guardar en ubicación alternativa\n",
        "        alt_file = f'./output_{timestamp}.abc'\n",
        "        try:\n",
        "            with open(alt_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(tunes)\n",
        "            print(f\"Melodías guardadas en ubicación alternativa: {alt_file}\")\n",
        "        except:\n",
        "            print(\"No se pudieron guardar las melodías generadas\")\n",
        "\n",
        "    return tunes\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# Puedes ejecutar la función directamente sin parámetros para usar valores predeterminados\n",
        "# generate_abc()\n",
        "\n",
        "# O con parámetros personalizados\n",
        "# generate_abc(num_tunes=5, temperature=1.3, top_p=0.95, top_k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xZzkbsFh6yk",
        "outputId": "36010cef-aaff-4387-c846-ce80fc84a295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Módulos importados correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_abc(num_tunes=1, temperature=0.1, top_p=0.95, top_k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od-3UbGvirbq",
        "outputId": "d83e98b8-ae8f-4295-e257-1fc7e724d440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando GPU: Tesla T4\n",
            "Modelo inicializado con 88425984 parámetros\n",
            "Cargando pesos desde '/content/drive/MyDrive/tunesformer-main/weights3.pth'...\n",
            "Error al cargar pesos: Error(s) in loading state_dict for CustomTunesFormer:\n",
            "\tUnexpected key(s) in state_dict: \"patch_level_decoder.base.h.0.attn.bias\", \"patch_level_decoder.base.h.0.attn.masked_bias\", \"patch_level_decoder.base.h.1.attn.bias\", \"patch_level_decoder.base.h.1.attn.masked_bias\", \"patch_level_decoder.base.h.2.attn.bias\", \"patch_level_decoder.base.h.2.attn.masked_bias\", \"patch_level_decoder.base.h.3.attn.bias\", \"patch_level_decoder.base.h.3.attn.masked_bias\", \"patch_level_decoder.base.h.4.attn.bias\", \"patch_level_decoder.base.h.4.attn.masked_bias\", \"patch_level_decoder.base.h.5.attn.bias\", \"patch_level_decoder.base.h.5.attn.masked_bias\", \"patch_level_decoder.base.h.6.attn.bias\", \"patch_level_decoder.base.h.6.attn.masked_bias\", \"patch_level_decoder.base.h.7.attn.bias\", \"patch_level_decoder.base.h.7.attn.masked_bias\", \"patch_level_decoder.base.h.8.attn.bias\", \"patch_level_decoder.base.h.8.attn.masked_bias\", \"char_level_decoder.base.transformer.h.0.attn.bias\", \"char_level_decoder.base.transformer.h.0.attn.masked_bias\", \"char_level_decoder.base.transformer.h.1.attn.bias\", \"char_level_decoder.base.transformer.h.1.attn.masked_bias\", \"char_level_decoder.base.transformer.h.2.attn.bias\", \"char_level_decoder.base.transformer.h.2.attn.masked_bias\". \n",
            "Intentando descargar pesos desde Hugging Face...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "weights3.pth: 100%|██████████| 0.99G/0.99G [00:14<00:00, 75.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error al descargar/cargar pesos: Error(s) in loading state_dict for CustomTunesFormer:\n",
            "\tUnexpected key(s) in state_dict: \"patch_level_decoder.base.h.0.attn.bias\", \"patch_level_decoder.base.h.0.attn.masked_bias\", \"patch_level_decoder.base.h.1.attn.bias\", \"patch_level_decoder.base.h.1.attn.masked_bias\", \"patch_level_decoder.base.h.2.attn.bias\", \"patch_level_decoder.base.h.2.attn.masked_bias\", \"patch_level_decoder.base.h.3.attn.bias\", \"patch_level_decoder.base.h.3.attn.masked_bias\", \"patch_level_decoder.base.h.4.attn.bias\", \"patch_level_decoder.base.h.4.attn.masked_bias\", \"patch_level_decoder.base.h.5.attn.bias\", \"patch_level_decoder.base.h.5.attn.masked_bias\", \"patch_level_decoder.base.h.6.attn.bias\", \"patch_level_decoder.base.h.6.attn.masked_bias\", \"patch_level_decoder.base.h.7.attn.bias\", \"patch_level_decoder.base.h.7.attn.masked_bias\", \"patch_level_decoder.base.h.8.attn.bias\", \"patch_level_decoder.base.h.8.attn.masked_bias\", \"char_level_decoder.base.transformer.h.0.attn.bias\", \"char_level_decoder.base.transformer.h.0.attn.masked_bias\", \"char_level_decoder.base.transformer.h.1.attn.bias\", \"char_level_decoder.base.transformer.h.1.attn.masked_bias\", \"char_level_decoder.base.transformer.h.2.attn.bias\", \"char_level_decoder.base.transformer.h.2.attn.masked_bias\". \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import argparse\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configurar CUDA para mejor debugging\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# Importar después de configurar CUDA\n",
        "from utils import *\n",
        "from config import *\n",
        "from transformers import GPT2Config\n",
        "\n",
        "def get_args(parser):\n",
        "    parser.add_argument('-num_tunes', type=int, default=1, help='the number of independently computed returned tunes')\n",
        "    parser.add_argument('-max_patch', type=int, default=16, help='integer to define the maximum length in tokens of each tune')\n",
        "    parser.add_argument('-top_p', type=float, default=0.9, help='float to define the tokens that are within the sample operation of text generation')\n",
        "    parser.add_argument('-top_k', type=int, default=10, help='integer to define the tokens that are within the sample operation of text generation')\n",
        "    parser.add_argument('-temperature', type=float, default=0.8, help='the temperature of the sampling operation')\n",
        "    parser.add_argument('-seed', type=int, default=42, help='seed for randomstate')\n",
        "    parser.add_argument('-show_control_code', type=bool, default=False, help='whether to show control code')\n",
        "    parser.add_argument('-voice', type=str, default='V1', choices=['V1', 'V2', 'V3', 'V4'], help='voice to generate')\n",
        "    parser.add_argument('-key', type=str, default='C', help='key signature')\n",
        "    parser.add_argument('-meter', type=str, default='4/4', help='time signature')\n",
        "    parser.add_argument('-weights', type=str, default='weights3.pth', help='path to model weights')\n",
        "\n",
        "    # Fix para Colab\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    return args\n",
        "\n",
        "def create_simple_prompt(voice='V1', key='C', meter='4/4'):\n",
        "    \"\"\"Crea un prompt muy simple para evitar problemas\"\"\"\n",
        "    # Prompt mínimo basado en tus datos de entrenamiento\n",
        "    control_code = f\"PIECE:gen123 VOICE:{voice} MEASURES:8 KEY:{key} METER:{meter} COMPLEXITY:SIMPLE\"\n",
        "    abc_header = f\"X:1\\nM:{meter}\\nK:{key}\\nV:{voice[-1]}\"\n",
        "\n",
        "    return control_code + \"\\n\" + abc_header\n",
        "\n",
        "def safe_model_load(model, checkpoint_path, device):\n",
        "    \"\"\"Carga el modelo de manera segura\"\"\"\n",
        "    try:\n",
        "        print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
        "\n",
        "        # Cargar en CPU primero\n",
        "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "        # Verificar estructura del checkpoint\n",
        "        if 'model' in checkpoint:\n",
        "            state_dict = checkpoint['model']\n",
        "            print(f\"Checkpoint info - Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
        "            if 'config' in checkpoint:\n",
        "                print(f\"Saved config: {checkpoint['config']}\")\n",
        "        else:\n",
        "            state_dict = checkpoint\n",
        "\n",
        "        # Verificar compatibilidad básica\n",
        "        model_keys = set(model.state_dict().keys())\n",
        "        checkpoint_keys = set(state_dict.keys())\n",
        "\n",
        "        if model_keys != checkpoint_keys:\n",
        "            print(\"Warning: Model structure mismatch\")\n",
        "            missing_keys = model_keys - checkpoint_keys\n",
        "            unexpected_keys = checkpoint_keys - model_keys\n",
        "            if missing_keys:\n",
        "                print(f\"Missing keys: {list(missing_keys)[:5]}...\")\n",
        "            if unexpected_keys:\n",
        "                print(f\"Unexpected keys: {list(unexpected_keys)[:5]}...\")\n",
        "\n",
        "        # Cargar state dict\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "        # Mover a device después de cargar\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        print(\"✅ Model loaded successfully!\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_abc(args):\n",
        "    # Configurar device\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
        "        # Limpiar cache de CUDA\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    try:\n",
        "        # Crear patchilizer\n",
        "        patchilizer = Patchilizer()\n",
        "        print(\"✅ Patchilizer created\")\n",
        "\n",
        "        # Configuración del modelo - usar valores más seguros\n",
        "        print(\"Creating model configuration...\")\n",
        "\n",
        "        # Valores por defecto más conservadores\n",
        "        patch_layers = getattr(config, 'PATCH_NUM_LAYERS', 6)\n",
        "        char_layers = getattr(config, 'CHAR_NUM_LAYERS', 6)\n",
        "        patch_length = getattr(config, 'PATCH_LENGTH', 128)\n",
        "        patch_size = getattr(config, 'PATCH_SIZE', 32)\n",
        "        share_weights = getattr(config, 'SHARE_WEIGHTS', True)\n",
        "\n",
        "        print(f\"Model config: patch_layers={patch_layers}, char_layers={char_layers}\")\n",
        "        print(f\"Patch config: length={patch_length}, size={patch_size}\")\n",
        "\n",
        "        patch_config = GPT2Config(\n",
        "            num_hidden_layers=patch_layers,\n",
        "            max_length=patch_length,\n",
        "            max_position_embeddings=patch_length,\n",
        "            vocab_size=1\n",
        "        )\n",
        "\n",
        "        char_config = GPT2Config(\n",
        "            num_hidden_layers=char_layers,\n",
        "            max_length=patch_size,\n",
        "            max_position_embeddings=patch_size,\n",
        "            vocab_size=128\n",
        "        )\n",
        "\n",
        "        # Crear modelo\n",
        "        print(\"Creating TunesFormer model...\")\n",
        "        model = TunesFormer(patch_config, char_config, share_weights=share_weights)\n",
        "        print(\"✅ Model created\")\n",
        "\n",
        "        # Cargar pesos\n",
        "        if not os.path.exists(args.weights):\n",
        "            print(f\"❌ Weights file '{args.weights}' not found!\")\n",
        "            return\n",
        "\n",
        "        model = safe_model_load(model, args.weights, device)\n",
        "        if model is None:\n",
        "            return\n",
        "\n",
        "        # Crear prompt simple\n",
        "        prompt = create_simple_prompt(args.voice, args.key, args.meter)\n",
        "        print(f\"Using prompt:\\n{prompt}\\n\")\n",
        "\n",
        "        # Parámetros de generación\n",
        "        max_patch = min(args.max_patch, 20)  # Limitar para evitar problemas\n",
        "\n",
        "        print(\" GENERATION PARAMETERS \".center(60, \"#\"))\n",
        "        print(f\"max_patch: {max_patch}\")\n",
        "        print(f\"temperature: {args.temperature}\")\n",
        "        print(f\"top_p: {args.top_p}\")\n",
        "        print(f\"top_k: {args.top_k}\")\n",
        "        print(\"\\n\" + \" OUTPUT \".center(60, \"#\"))\n",
        "\n",
        "        all_tunes = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i in range(args.num_tunes):\n",
        "            print(f\"\\n--- Generating Tune {i+1}/{args.num_tunes} ---\")\n",
        "\n",
        "            try:\n",
        "                # Mostrar prompt inicial\n",
        "                if args.show_control_code:\n",
        "                    display_text = prompt\n",
        "                else:\n",
        "                    # Solo mostrar la parte ABC\n",
        "                    lines = prompt.split('\\n')\n",
        "                    abc_start = next((j for j, line in enumerate(lines) if line.startswith('X:')), 0)\n",
        "                    display_text = '\\n'.join(lines[abc_start:])\n",
        "\n",
        "                print(\"Starting with:\")\n",
        "                print(display_text)\n",
        "                print(\"\\nGenerating...\")\n",
        "\n",
        "                # Codificar prompt de manera segura\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        encoded = patchilizer.encode(prompt, add_special_patches=True)\n",
        "\n",
        "                        if len(encoded) == 0:\n",
        "                            print(\"❌ Empty encoding\")\n",
        "                            continue\n",
        "\n",
        "                        # Preparar input patches\n",
        "                        if len(encoded) > 1:\n",
        "                            encoded = encoded[:-1]  # Quitar último token\n",
        "\n",
        "                        input_patches = torch.tensor([encoded], device=device, dtype=torch.long)\n",
        "                        print(f\"Input shape: {input_patches.shape}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Encoding error: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # Generación paso a paso\n",
        "                generated_text = display_text\n",
        "\n",
        "                for step in range(max_patch):\n",
        "                    try:\n",
        "                        with torch.no_grad():\n",
        "                            # Generación simple\n",
        "                            outputs = model(input_patches)\n",
        "\n",
        "                            if hasattr(outputs, 'logits'):\n",
        "                                logits = outputs.logits[:, -1, :]  # Último token\n",
        "\n",
        "                                # Sampling manual simple\n",
        "                                if args.temperature > 0:\n",
        "                                    logits = logits / args.temperature\n",
        "\n",
        "                                probs = torch.softmax(logits, dim=-1)\n",
        "                                next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "                                # Verificar si es EOS\n",
        "                                if hasattr(patchilizer, 'eos_token_id') and next_token.item() == patchilizer.eos_token_id:\n",
        "                                    print(\"\\n[EOS reached]\")\n",
        "                                    break\n",
        "\n",
        "                                # Decodificar\n",
        "                                try:\n",
        "                                    decoded = patchilizer.decode([next_token.item()])\n",
        "                                    if decoded:\n",
        "                                        print(decoded, end=\"\", flush=True)\n",
        "                                        generated_text += decoded\n",
        "\n",
        "                                        # Actualizar input para siguiente iteración\n",
        "                                        input_patches = torch.cat([input_patches, next_token.unsqueeze(0)], dim=1)\n",
        "                                    else:\n",
        "                                        break\n",
        "\n",
        "                                except Exception as e:\n",
        "                                    print(f\"\\n[Decode error: {e}]\")\n",
        "                                    break\n",
        "                            else:\n",
        "                                print(\"\\n[No logits in output]\")\n",
        "                                break\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n[Generation error at step {step}: {e}]\")\n",
        "                        break\n",
        "\n",
        "                all_tunes.append(generated_text)\n",
        "                print(f\"\\n\\n✅ Tune {i+1} completed!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error generating tune {i+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Guardar resultados\n",
        "        print(f\"\\nGeneration time: {time.time()-start_time:.2f} seconds\")\n",
        "\n",
        "        if all_tunes:\n",
        "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
        "            os.makedirs('output_tunes', exist_ok=True)\n",
        "\n",
        "            output_file = f'output_tunes/tune_{timestamp}_{args.voice}_{args.key}.abc'\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                f.write('\\n\\n'.join(all_tunes))\n",
        "\n",
        "            print(f\"✅ Saved {len(all_tunes)} tune(s) to: {output_file}\")\n",
        "\n",
        "            # Mostrar resultado\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"GENERATED MUSIC:\")\n",
        "            print(\"=\"*50)\n",
        "            result = all_tunes[0]\n",
        "            print(result[:300] + (\"...\" if len(result) > 300 else \"\"))\n",
        "        else:\n",
        "            print(\"❌ No tunes generated successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Fatal error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description='Generate music with TunesFormer')\n",
        "    args = get_args(parser)\n",
        "\n",
        "    print(\"🎵 TunesFormer Music Generator (Safe Mode)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        generate_abc(args)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n⏹️ Generation interrupted by user\")\n",
        "    except Exception as e:\n",
        "        print(f\"💥 Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlCTnPrlcKv6",
        "outputId": "a80707f7-8549-4a84-f9cc-b73f894bd01c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎵 TunesFormer Music Generator (Safe Mode)\n",
            "============================================================\n",
            "Using GPU: Tesla T4\n",
            "✅ Patchilizer created\n",
            "Creating model configuration...\n",
            "❌ Fatal error: name 'config' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-fc16222eb7a8>\", line 107, in generate_abc\n",
            "    patch_layers = getattr(config, 'PATCH_NUM_LAYERS', 6)\n",
            "                           ^^^^^^\n",
            "NameError: name 'config' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nueva forma para entrenar modelo, aún no provada"
      ],
      "metadata": {
        "id": "7IoYn59odRjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from utils import *\n",
        "from config import *\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Config, get_scheduler\n",
        "\n",
        "# Fix para determinismo\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# CONFIGURACIÓN OPTIMIZADA\n",
        "BATCH_SIZE = 4  # Batch size fijo y mayor\n",
        "LEARNING_RATE = 1e-5  # Learning rate más conservador\n",
        "GRADIENT_CLIP = 1.0  # Gradient clipping\n",
        "WEIGHT_DECAY = 0.01  # Weight decay para regularización\n",
        "WARMUP_RATIO = 0.1  # 10% de warmup\n",
        "EVAL_STEPS = 100  # Evaluar cada 100 steps\n",
        "SAVE_STEPS = 500  # Guardar cada 500 steps\n",
        "PATIENCE = 5  # Early stopping patience\n",
        "\n",
        "patchilizer = Patchilizer()\n",
        "\n",
        "patch_config = GPT2Config(\n",
        "    num_hidden_layers=PATCH_NUM_LAYERS,\n",
        "    max_length=PATCH_LENGTH,\n",
        "    max_position_embeddings=PATCH_LENGTH,\n",
        "    vocab_size=1,\n",
        "    hidden_dropout_prob=0.1,  # Añadir dropout\n",
        "    attention_probs_dropout_prob=0.1\n",
        ")\n",
        "\n",
        "char_config = GPT2Config(\n",
        "    num_hidden_layers=CHAR_NUM_LAYERS,\n",
        "    max_length=PATCH_SIZE,\n",
        "    max_position_embeddings=PATCH_SIZE,\n",
        "    vocab_size=128,\n",
        "    hidden_dropout_prob=0.1,  # Añadir dropout\n",
        "    attention_probs_dropout_prob=0.1\n",
        ")\n",
        "\n",
        "model = TunesFormer(patch_config, char_config, share_weights=SHARE_WEIGHTS)\n",
        "\n",
        "# Print parameter number\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Parameter Number: {total_params:,}\")\n",
        "\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "scaler = GradScaler()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    betas=(0.9, 0.999),\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    input_patches = []\n",
        "\n",
        "    for input_patch in batch:\n",
        "        input_patches.append(input_patch.reshape(-1))\n",
        "\n",
        "    input_patches = torch.nn.utils.rnn.pad_sequence(\n",
        "        input_patches, batch_first=True, padding_value=0\n",
        "    )\n",
        "\n",
        "    return input_patches.to(device)\n",
        "\n",
        "def split_data(data, eval_ratio=0.15):  # Más datos para evaluación\n",
        "    random.shuffle(data)\n",
        "    split_idx = int(len(data) * eval_ratio)\n",
        "    eval_set = data[:split_idx]\n",
        "    train_set = data[split_idx:]\n",
        "    return train_set, eval_set\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, items, max_length=None):\n",
        "        self.texts = []\n",
        "        failed_items = 0\n",
        "\n",
        "        print(f\"Processing {len(items)} items...\")\n",
        "\n",
        "        for item in tqdm(items, desc=\"Encoding data\"):\n",
        "            # FIX: No remover la primera línea de ABC notation\n",
        "            control_code = item['control code'].strip()\n",
        "            abc_notation = item['abc notation'].strip()\n",
        "\n",
        "            # Combinar correctamente\n",
        "            text = control_code + \"\\n\" + abc_notation\n",
        "\n",
        "            try:\n",
        "                input_patch = patchilizer.encode(text, add_special_patches=True)\n",
        "                input_patch = torch.tensor(input_patch, dtype=torch.long)\n",
        "\n",
        "                # Filtrar secuencias muy cortas o muy largas\n",
        "                if len(input_patch) < 10:\n",
        "                    failed_items += 1\n",
        "                    continue\n",
        "\n",
        "                if max_length and len(input_patch) > max_length:\n",
        "                    input_patch = input_patch[:max_length]\n",
        "\n",
        "                if torch.sum(input_patch) != 0:\n",
        "                    self.texts.append(input_patch)\n",
        "                else:\n",
        "                    failed_items += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_items += 1\n",
        "                continue\n",
        "\n",
        "        print(f\"Successfully processed: {len(self.texts)} items\")\n",
        "        print(f\"Failed items: {failed_items}\")\n",
        "\n",
        "        if len(self.texts) == 0:\n",
        "            raise ValueError(\"No valid training data found!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "def process_one_batch(batch):\n",
        "    input_patches = batch\n",
        "    outputs = model(input_patches)\n",
        "    loss = outputs.loss\n",
        "    return loss.mean() if loss is not None else None\n",
        "\n",
        "def train_epoch(train_loader, eval_loader, epoch):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    num_batches = 0\n",
        "    step = 0\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        try:\n",
        "            # Forward pass con mixed precision\n",
        "            with autocast():\n",
        "                loss = process_one_batch(batch)\n",
        "\n",
        "            if loss is None or torch.isnan(loss):\n",
        "                continue\n",
        "\n",
        "            # Backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP)\n",
        "\n",
        "            # Optimizer step\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            lr_scheduler.step()\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            num_batches += 1\n",
        "            step += 1\n",
        "\n",
        "            # Update progress bar\n",
        "            avg_loss = total_train_loss / num_batches\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{avg_loss:.4f}',\n",
        "                'lr': f'{lr_scheduler.get_last_lr()[0]:.2e}'\n",
        "            })\n",
        "\n",
        "            # Evaluación periódica\n",
        "            if step % EVAL_STEPS == 0:\n",
        "                eval_loss = eval_epoch(eval_loader, verbose=False)\n",
        "                model.train()  # Volver a training mode\n",
        "\n",
        "                print(f\"\\nStep {step} - Train Loss: {avg_loss:.4f}, Eval Loss: {eval_loss:.4f}\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"memory\" in str(e):\n",
        "                print(f\"CUDA OOM: {e}\")\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "    return total_train_loss / max(num_batches, 1)\n",
        "\n",
        "def eval_epoch(eval_loader, verbose=True):\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    progress_bar = tqdm(eval_loader, desc=\"Evaluating\") if verbose else eval_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            try:\n",
        "                loss = process_one_batch(batch)\n",
        "\n",
        "                if loss is None or torch.isnan(loss):\n",
        "                    continue\n",
        "\n",
        "                total_eval_loss += loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "                if verbose:\n",
        "                    avg_loss = total_eval_loss / num_batches\n",
        "                    progress_bar.set_postfix({'eval_loss': f'{avg_loss:.4f}'})\n",
        "\n",
        "            except RuntimeError as e:\n",
        "                if \"memory\" in str(e):\n",
        "                    torch.cuda.empty_cache()\n",
        "                    continue\n",
        "                else:\n",
        "                    raise e\n",
        "\n",
        "    return total_eval_loss / max(num_batches, 1)\n",
        "\n",
        "# CONFIGURACIÓN DE ENTRENAMIENTO\n",
        "NUM_EPOCHS = 50\n",
        "LOAD_FROM_CHECKPOINT = True\n",
        "CHECKPOINT_PATH = 'weights_optimized.pth'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Cargar y validar datos\n",
        "    print(\"Loading data...\")\n",
        "\n",
        "    # Verificar que el archivo existe\n",
        "    data_file = 'data_curation/data_training_ready.json'\n",
        "    if not os.path.exists(data_file):\n",
        "        print(f\"Data file {data_file} not found!\")\n",
        "        exit(1)\n",
        "\n",
        "    with open(data_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Total data items: {len(data)}\")\n",
        "\n",
        "    # Verificar muestra de datos\n",
        "    if len(data) > 0:\n",
        "        sample = data[0]\n",
        "        print(f\"Sample control code: {sample['control code'][:100]}...\")\n",
        "        print(f\"Sample ABC notation: {sample['abc notation'][:100]}...\")\n",
        "\n",
        "    # Dividir datos\n",
        "    train_data, eval_data = split_data(data)\n",
        "    print(f\"Train items: {len(train_data)}, Eval items: {len(eval_data)}\")\n",
        "\n",
        "    # Crear datasets y dataloaders\n",
        "    train_dataset = MyDataset(train_data, max_length=PATCH_LENGTH)\n",
        "    eval_dataset = MyDataset(eval_data, max_length=PATCH_LENGTH)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        collate_fn=collate_batch,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    eval_loader = DataLoader(\n",
        "        eval_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        collate_fn=collate_batch,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"Train batches: {len(train_loader)}, Eval batches: {len(eval_loader)}\")\n",
        "\n",
        "    # Configurar learning rate scheduler\n",
        "    total_steps = NUM_EPOCHS * len(train_loader)\n",
        "    warmup_steps = int(total_steps * WARMUP_RATIO)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=\"cosine\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=warmup_steps,\n",
        "        num_training_steps=total_steps,\n",
        "    )\n",
        "\n",
        "    # Cargar checkpoint si existe\n",
        "    start_epoch = 0\n",
        "    best_eval_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    if LOAD_FROM_CHECKPOINT and os.path.exists(CHECKPOINT_PATH):\n",
        "        print(f\"Loading checkpoint from {CHECKPOINT_PATH}\")\n",
        "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model.module.load_state_dict(checkpoint['model'])\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_eval_loss = checkpoint['best_eval_loss']\n",
        "\n",
        "        print(f\"Resumed from epoch {start_epoch}, best eval loss: {best_eval_loss:.4f}\")\n",
        "\n",
        "    # Mover modelo a device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loop de entrenamiento\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(start_epoch, NUM_EPOCHS):\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        # Entrenar\n",
        "        train_loss = train_epoch(train_loader, eval_loader, epoch+1)\n",
        "\n",
        "        # Evaluar\n",
        "        eval_loss = eval_epoch(eval_loader)\n",
        "\n",
        "        # Log\n",
        "        print(f\"\\nEpoch {epoch+1} Results:\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Eval Loss: {eval_loss:.4f}\")\n",
        "        print(f\"Learning Rate: {lr_scheduler.get_last_lr()[0]:.2e}\")\n",
        "\n",
        "        # Guardar logs\n",
        "        with open('training_logs_optimized.txt', 'a') as f:\n",
        "            f.write(f\"Epoch {epoch+1}\\n\")\n",
        "            f.write(f\"Train Loss: {train_loss:.4f}\\n\")\n",
        "            f.write(f\"Eval Loss: {eval_loss:.4f}\\n\")\n",
        "            f.write(f\"Time: {time.asctime()}\\n\\n\")\n",
        "\n",
        "        # Guardar mejor modelo\n",
        "        if eval_loss < best_eval_loss:\n",
        "            best_eval_loss = eval_loss\n",
        "            patience_counter = 0\n",
        "\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model': model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'lr_scheduler': lr_scheduler.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'best_eval_loss': best_eval_loss,\n",
        "                'config': {\n",
        "                    'PATCH_NUM_LAYERS': PATCH_NUM_LAYERS,\n",
        "                    'CHAR_NUM_LAYERS': CHAR_NUM_LAYERS,\n",
        "                    'PATCH_LENGTH': PATCH_LENGTH,\n",
        "                    'PATCH_SIZE': PATCH_SIZE\n",
        "                }\n",
        "            }\n",
        "\n",
        "            torch.save(checkpoint, CHECKPOINT_PATH)\n",
        "            print(f\"✅ New best model saved! Eval loss: {eval_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"⚠️  No improvement. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f\"🛑 Early stopping triggered after {PATIENCE} epochs without improvement\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n🏆 Training completed!\")\n",
        "    print(f\"Best Eval Loss: {best_eval_loss:.4f}\")\n",
        "    print(f\"Model saved at: {CHECKPOINT_PATH}\")"
      ],
      "metadata": {
        "id": "Pg-i9cKkdUv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}