{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f44b8ba4f8af44858a290fab9c1aad5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57b0dfae22974f7f97136e8b70e4da64",
              "IPY_MODEL_ece8e78f52774c5a9e10f61d1697ac78",
              "IPY_MODEL_1a761bab056e4241b75d53ecc99c52ab"
            ],
            "layout": "IPY_MODEL_2ce9ba6e9f6342caa89a42a475c47e7c"
          }
        },
        "57b0dfae22974f7f97136e8b70e4da64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b20a22317c442229371e910eb9cf1c7",
            "placeholder": "​",
            "style": "IPY_MODEL_432f93a0fa684bec9f0c13b160d3d916",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ece8e78f52774c5a9e10f61d1697ac78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a504d5eb850744f2a6b799f838d42a93",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d91a66e0d414b9abe27b466c50ea22a",
            "value": 2
          }
        },
        "1a761bab056e4241b75d53ecc99c52ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb899c1afe74afb8b72fee0d1405619",
            "placeholder": "​",
            "style": "IPY_MODEL_403df6e51ef7480d8ab80f4b2bf8ea7b",
            "value": " 2/2 [00:00&lt;00:00,  6.25it/s]"
          }
        },
        "2ce9ba6e9f6342caa89a42a475c47e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b20a22317c442229371e910eb9cf1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432f93a0fa684bec9f0c13b160d3d916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a504d5eb850744f2a6b799f838d42a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d91a66e0d414b9abe27b466c50ea22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cbb899c1afe74afb8b72fee0d1405619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403df6e51ef7480d8ab80f4b2bf8ea7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/tunesformer-main/')  # Cambia el directorio\n",
        "print(os.getcwd())    # Muestra el directorio actual, debe salir /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CfwFstPc-v3",
        "outputId": "833cbc02-7d63-4858-fcd1-f7d68a12baa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/tunesformer-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "f44b8ba4f8af44858a290fab9c1aad5b",
            "57b0dfae22974f7f97136e8b70e4da64",
            "ece8e78f52774c5a9e10f61d1697ac78",
            "1a761bab056e4241b75d53ecc99c52ab",
            "2ce9ba6e9f6342caa89a42a475c47e7c",
            "0b20a22317c442229371e910eb9cf1c7",
            "432f93a0fa684bec9f0c13b160d3d916",
            "a504d5eb850744f2a6b799f838d42a93",
            "4d91a66e0d414b9abe27b466c50ea22a",
            "cbb899c1afe74afb8b72fee0d1405619",
            "403df6e51ef7480d8ab80f4b2bf8ea7b"
          ]
        },
        "id": "y31Lt9l9cdrL",
        "outputId": "9211d11e-2167-470b-ed90-95dc7f6f56c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando modelo y tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f44b8ba4f8af44858a290fab9c1aad5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente\n",
            "Procesando datos ABC...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando archivos ABC: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se procesaron 0 registros ABC válidos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generando muestras de entrenamiento: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se generaron 0 muestras de entrenamiento\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "--load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.NO\n- Save strategy: SaveStrategy.STEPS",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dabd5af53191>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-dabd5af53191>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;31m# Entrenar modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m     trainer.train(\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mabc_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mABC_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-dabd5af53191>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, abc_directory, output_dir, num_epochs, batch_size, learning_rate, max_length, save_steps)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# Configurar argumentos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, tp_size, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim...\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model_at_end\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mSaveStrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBEST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1649\u001b[0m                     \u001b[0;34m\"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                     \u001b[0;34mf\"strategy: {self.eval_strategy}\\n- Save strategy: {self.save_strategy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: IntervalStrategy.NO\n- Save strategy: SaveStrategy.STEPS"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from string import Template\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "@dataclass\n",
        "class ABCRecord:\n",
        "    \"\"\"Estructura para almacenar datos ABC procesados\"\"\"\n",
        "    index: str\n",
        "    title: str\n",
        "    composer: str\n",
        "    meter: str\n",
        "    length: str\n",
        "    key: str\n",
        "    rhythm: str\n",
        "    area: str\n",
        "    source: str\n",
        "    notes: str\n",
        "    abc_content: str\n",
        "    full_abc: str\n",
        "\n",
        "class ABCProcessor:\n",
        "    \"\"\"Procesador para datos ABC notation\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.abc_pattern = re.compile(r'X:\\s*(\\d+)\\s*\\n((?:[^X]|X(?!\\s*\\d))*?)(?=X:\\s*\\d|\\Z)', re.MULTILINE | re.DOTALL)\n",
        "        self.field_patterns = {\n",
        "            'T': re.compile(r'^T:\\s*(.+)$', re.MULTILINE),\n",
        "            'C': re.compile(r'^C:\\s*(.+)$', re.MULTILINE),\n",
        "            'M': re.compile(r'^M:\\s*(.+)$', re.MULTILINE),\n",
        "            'L': re.compile(r'^L:\\s*(.+)$', re.MULTILINE),\n",
        "            'K': re.compile(r'^K:\\s*(.+)$', re.MULTILINE),\n",
        "            'R': re.compile(r'^R:\\s*(.+)$', re.MULTILINE),\n",
        "            'A': re.compile(r'^A:\\s*(.+)$', re.MULTILINE),\n",
        "            'S': re.compile(r'^S:\\s*(.+)$', re.MULTILINE),\n",
        "            'N': re.compile(r'^N:\\s*(.+)$', re.MULTILINE)\n",
        "        }\n",
        "\n",
        "    def parse_abc_file(self, file_path: str) -> List[ABCRecord]:\n",
        "        \"\"\"Parsea un archivo ABC y extrae todas las canciones\"\"\"\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        return self.parse_abc_content(content)\n",
        "\n",
        "    def parse_abc_content(self, content: str) -> List[ABCRecord]:\n",
        "        \"\"\"Parsea contenido ABC y extrae todas las canciones\"\"\"\n",
        "        records = []\n",
        "        matches = self.abc_pattern.findall(content)\n",
        "\n",
        "        for index, abc_body in matches:\n",
        "            full_abc = f\"X:{index}\\n{abc_body}\"\n",
        "            record = self._extract_fields(index, abc_body, full_abc)\n",
        "            if record:\n",
        "                records.append(record)\n",
        "\n",
        "        return records\n",
        "\n",
        "    def _extract_fields(self, index: str, abc_body: str, full_abc: str) -> Optional[ABCRecord]:\n",
        "        \"\"\"Extrae campos individuales del contenido ABC\"\"\"\n",
        "        try:\n",
        "            # Extraer campos usando regex\n",
        "            fields = {}\n",
        "            for field, pattern in self.field_patterns.items():\n",
        "                match = pattern.search(abc_body)\n",
        "                fields[field] = match.group(1).strip() if match else \"\"\n",
        "\n",
        "            # Extraer las notas musicales (después del campo K:)\n",
        "            notes_match = re.search(r'K:\\s*[^\\n]*\\n(.*)', abc_body, re.DOTALL)\n",
        "            notes = notes_match.group(1).strip() if notes_match else \"\"\n",
        "\n",
        "            # Limpiar notas de comentarios y líneas vacías\n",
        "            notes_lines = []\n",
        "            for line in notes.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if line and not line.startswith('%'):\n",
        "                    notes_lines.append(line)\n",
        "            notes = '\\n'.join(notes_lines)\n",
        "\n",
        "            return ABCRecord(\n",
        "                index=index,\n",
        "                title=fields.get('T', f\"Untitled {index}\"),\n",
        "                composer=fields.get('C', \"Unknown\"),\n",
        "                meter=fields.get('M', \"4/4\"),\n",
        "                length=fields.get('L', \"1/8\"),\n",
        "                key=fields.get('K', \"C\"),\n",
        "                rhythm=fields.get('R', \"\"),\n",
        "                area=fields.get('A', \"\"),\n",
        "                source=fields.get('S', \"\"),\n",
        "                notes=fields.get('N', \"\"),\n",
        "                abc_content=notes,\n",
        "                full_abc=full_abc\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando ABC {index}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def validate_abc(self, record: ABCRecord) -> bool:\n",
        "        \"\"\"Valida que el registro ABC tenga campos mínimos requeridos\"\"\"\n",
        "        return bool(record.key and record.meter and record.abc_content)\n",
        "\n",
        "    def process_directory(self, directory_path: str) -> List[ABCRecord]:\n",
        "        \"\"\"Procesa todos los archivos ABC en un directorio\"\"\"\n",
        "        all_records = []\n",
        "        abc_files = list(Path(directory_path).glob(\"*.abc\"))\n",
        "\n",
        "        for file_path in tqdm(abc_files, desc=\"Procesando archivos ABC\"):\n",
        "            try:\n",
        "                records = self.parse_abc_file(str(file_path))\n",
        "                valid_records = [r for r in records if self.validate_abc(r)]\n",
        "                all_records.extend(valid_records)\n",
        "                print(f\"Procesado {file_path.name}: {len(valid_records)} registros válidos\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error procesando {file_path}: {e}\")\n",
        "\n",
        "        return all_records\n",
        "\n",
        "class MusicInstructionGenerator:\n",
        "    \"\"\"Genera instrucciones de entrenamiento para tareas musicales\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.prompt_template = Template(\"Human: ${inst} </s> Assistant: \")\n",
        "\n",
        "        # Plantillas de instrucciones\n",
        "        self.instruction_templates = {\n",
        "            'generation': [\n",
        "                \"Compone una pieza musical en {key} con métrica {meter}\",\n",
        "                \"Crea una melodía en estilo {rhythm} en la tonalidad de {key}\",\n",
        "                \"Desarrolla una composición usando la métrica {meter}\",\n",
        "                \"Genera una pieza musical inspirada en {area} usando {key}\",\n",
        "            ],\n",
        "            'analysis': [\n",
        "                \"Analiza esta pieza musical y describe su estructura:\",\n",
        "                \"Identifica los elementos musicales principales en:\",\n",
        "                \"Describe las características de esta composición:\",\n",
        "                \"Examina los aspectos técnicos de:\",\n",
        "            ],\n",
        "            'harmonization': [\n",
        "                \"Proporciona una armonización para esta melodía:\",\n",
        "                \"Añade acordes apropiados a:\",\n",
        "                \"Crea progresiones armónicas para:\",\n",
        "                \"Desarrolla acompañamiento para:\",\n",
        "            ],\n",
        "            'variation': [\n",
        "                \"Crea variaciones de este tema musical:\",\n",
        "                \"Desarrolla ornamentaciones para:\",\n",
        "                \"Genera embellecimientos para:\",\n",
        "                \"Produce variaciones melódicas de:\",\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def generate_training_samples(self, records: List[ABCRecord]) -> List[Dict]:\n",
        "        \"\"\"Genera muestras de entrenamiento a partir de registros ABC\"\"\"\n",
        "        training_samples = []\n",
        "\n",
        "        for record in tqdm(records, desc=\"Generando muestras de entrenamiento\"):\n",
        "            # Generar múltiples tipos de instrucciones por registro\n",
        "            samples = []\n",
        "\n",
        "            # 1. Generación musical condicionada\n",
        "            samples.extend(self._create_generation_samples(record))\n",
        "\n",
        "            # 2. Análisis musical\n",
        "            samples.extend(self._create_analysis_samples(record))\n",
        "\n",
        "            # 3. Tareas de armonización\n",
        "            if len(record.abc_content.split('\\n')) > 1:\n",
        "                samples.extend(self._create_harmonization_samples(record))\n",
        "\n",
        "            training_samples.extend(samples)\n",
        "\n",
        "        return training_samples\n",
        "\n",
        "    def _create_generation_samples(self, record: ABCRecord) -> List[Dict]:\n",
        "        \"\"\"Crea muestras de generación musical\"\"\"\n",
        "        samples = []\n",
        "        templates = self.instruction_templates['generation']\n",
        "\n",
        "        for template in templates[:2]:  # Usar solo 2 templates para evitar redundancia\n",
        "            instruction = template.format(\n",
        "                key=record.key,\n",
        "                meter=record.meter,\n",
        "                rhythm=record.rhythm or \"tradicional\",\n",
        "                area=record.area or \"clásico\"\n",
        "            )\n",
        "\n",
        "            sample = {\n",
        "                'instruction': instruction,\n",
        "                'response': record.full_abc,\n",
        "                'type': 'generation'\n",
        "            }\n",
        "            samples.append(sample)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _create_analysis_samples(self, record: ABCRecord) -> List[Dict]:\n",
        "        \"\"\"Crea muestras de análisis musical\"\"\"\n",
        "        samples = []\n",
        "        template = random.choice(self.instruction_templates['analysis'])\n",
        "\n",
        "        # Crear descripción analítica\n",
        "        analysis = self._generate_analysis_text(record)\n",
        "\n",
        "        sample = {\n",
        "            'instruction': f\"{template}\\n\\n{record.full_abc}\",\n",
        "            'response': analysis,\n",
        "            'type': 'analysis'\n",
        "        }\n",
        "        samples.append(sample)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _create_harmonization_samples(self, record: ABCRecord) -> List[Dict]:\n",
        "        \"\"\"Crea muestras de armonización\"\"\"\n",
        "        samples = []\n",
        "\n",
        "        # Extraer solo la melodía principal (primera línea de notas)\n",
        "        melody_lines = record.abc_content.split('\\n')\n",
        "        if len(melody_lines) > 0:\n",
        "            melody = melody_lines[0]\n",
        "            template = random.choice(self.instruction_templates['harmonization'])\n",
        "\n",
        "            # Crear ABC solo con la melodía\n",
        "            melody_abc = f\"X:{record.index}\\nT:{record.title}\\nM:{record.meter}\\nL:{record.length}\\nK:{record.key}\\n{melody}\"\n",
        "\n",
        "            sample = {\n",
        "                'instruction': f\"{template}\\n\\n{melody_abc}\",\n",
        "                'response': record.full_abc,\n",
        "                'type': 'harmonization'\n",
        "            }\n",
        "            samples.append(sample)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def _generate_analysis_text(self, record: ABCRecord) -> str:\n",
        "        \"\"\"Genera texto de análisis musical\"\"\"\n",
        "        analysis_parts = []\n",
        "\n",
        "        # Información básica\n",
        "        analysis_parts.append(f\"Esta pieza está en la tonalidad de {record.key} con métrica {record.meter}.\")\n",
        "\n",
        "        if record.rhythm:\n",
        "            analysis_parts.append(f\"Es un {record.rhythm}.\")\n",
        "\n",
        "        if record.composer and record.composer != \"Unknown\":\n",
        "            analysis_parts.append(f\"Compuesta por {record.composer}.\")\n",
        "\n",
        "        # Análisis estructural básico\n",
        "        lines = record.abc_content.split('\\n')\n",
        "        analysis_parts.append(f\"La pieza consta de {len(lines)} líneas melódicas.\")\n",
        "\n",
        "        # Detectar repeticiones\n",
        "        if ':|' in record.abc_content or '|:' in record.abc_content:\n",
        "            analysis_parts.append(\"Contiene secciones con repeticiones indicadas por barras de repetición.\")\n",
        "\n",
        "        # Detectar ornamentaciones\n",
        "        if any(char in record.abc_content for char in ['~', '^', '_', '=']):\n",
        "            analysis_parts.append(\"Incluye ornamentaciones y alteraciones accidentales.\")\n",
        "\n",
        "        return \" \".join(analysis_parts)\n",
        "\n",
        "    def format_for_training(self, samples: List[Dict]) -> List[str]:\n",
        "        \"\"\"Formatea las muestras para entrenamiento\"\"\"\n",
        "        formatted_samples = []\n",
        "\n",
        "        for sample in samples:\n",
        "            prompt = self.prompt_template.safe_substitute({\"inst\": sample['instruction']})\n",
        "            full_text = prompt + sample['response']\n",
        "            formatted_samples.append(full_text)\n",
        "\n",
        "        return formatted_samples\n",
        "\n",
        "class MusicDataset(Dataset):\n",
        "    \"\"\"Dataset personalizado para datos musicales\"\"\"\n",
        "\n",
        "    def __init__(self, texts: List[str], tokenizer, max_length: int = 2048):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        # Tokenizar\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': encoding['input_ids'].flatten()\n",
        "        }\n",
        "\n",
        "class ChatMusicianTrainer:\n",
        "    \"\"\"Entrenador principal para ChatMusician\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"m-a-p/ChatMusician\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "\n",
        "    def setup_model(self, output_dir: str = \"./chatmusician-finetuned\"):\n",
        "        \"\"\"Configura el modelo y tokenizer\"\"\"\n",
        "        print(\"Cargando modelo y tokenizer...\")\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.model_name,\n",
        "            trust_remote_code=True,\n",
        "            padding_side=\"right\"\n",
        "        )\n",
        "\n",
        "        # Añadir token de padding si no existe\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_name,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Habilitar gradient checkpointing para ahorrar memoria\n",
        "        self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        print(\"Modelo cargado exitosamente\")\n",
        "\n",
        "    def prepare_training_data(self, abc_directory: str) -> Tuple[List[str], List[Dict]]:\n",
        "        \"\"\"Procesa datos ABC y genera muestras de entrenamiento\"\"\"\n",
        "        print(\"Procesando datos ABC...\")\n",
        "\n",
        "        # Procesar archivos ABC\n",
        "        processor = ABCProcessor()\n",
        "        records = processor.process_directory(abc_directory)\n",
        "        print(f\"Se procesaron {len(records)} registros ABC válidos\")\n",
        "\n",
        "        # Generar instrucciones de entrenamiento\n",
        "        instructor = MusicInstructionGenerator()\n",
        "        training_samples = instructor.generate_training_samples(records)\n",
        "        print(f\"Se generaron {len(training_samples)} muestras de entrenamiento\")\n",
        "\n",
        "        # Formatear para entrenamiento\n",
        "        formatted_texts = instructor.format_for_training(training_samples)\n",
        "\n",
        "        return formatted_texts, training_samples\n",
        "\n",
        "    def train(self,\n",
        "              abc_directory: str,\n",
        "              output_dir: str = \"./chatmusician-finetuned\",\n",
        "              num_epochs: int = 3,\n",
        "              batch_size: int = 4,\n",
        "              learning_rate: float = 2e-5,\n",
        "              max_length: int = 2048,\n",
        "              save_steps: int = 500):\n",
        "        \"\"\"Entrena el modelo con datos ABC\"\"\"\n",
        "\n",
        "        # Configurar modelo\n",
        "        self.setup_model(output_dir)\n",
        "\n",
        "        # Preparar datos\n",
        "        formatted_texts, training_samples = self.prepare_training_data(abc_directory)\n",
        "\n",
        "        # Dividir en train/validation\n",
        "        split_idx = int(len(formatted_texts) * 0.9)\n",
        "        train_texts = formatted_texts[:split_idx]\n",
        "        val_texts = formatted_texts[split_idx:]\n",
        "\n",
        "        # Crear datasets\n",
        "        train_dataset = MusicDataset(train_texts, self.tokenizer, max_length)\n",
        "        val_dataset = MusicDataset(val_texts, self.tokenizer, max_length)\n",
        "\n",
        "        # Configurar argumentos de entrenamiento\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=num_epochs,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            gradient_accumulation_steps=4,\n",
        "            warmup_steps=100,\n",
        "            learning_rate=learning_rate,\n",
        "            fp16=True,\n",
        "            logging_steps=50,\n",
        "            save_steps=save_steps,\n",
        "            eval_steps=save_steps,\n",
        "            #evaluation_strategy=\"steps\",\n",
        "            save_total_limit=3,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            dataloader_num_workers=4,\n",
        "            remove_unused_columns=False,\n",
        "        )\n",
        "\n",
        "        # Data collator\n",
        "        data_collator = DataCollatorForLanguageModeling(\n",
        "            tokenizer=self.tokenizer,\n",
        "            mlm=False,\n",
        "        )\n",
        "\n",
        "        # Crear trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "\n",
        "        # Entrenar\n",
        "        print(\"Iniciando entrenamiento...\")\n",
        "        trainer.train()\n",
        "\n",
        "        # Guardar modelo final\n",
        "        trainer.save_model()\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        # Guardar metadatos del entrenamiento\n",
        "        with open(os.path.join(output_dir, \"training_info.json\"), 'w') as f:\n",
        "            json.dump({\n",
        "                'total_samples': len(formatted_texts),\n",
        "                'train_samples': len(train_texts),\n",
        "                'val_samples': len(val_texts),\n",
        "                'epochs': num_epochs,\n",
        "                'batch_size': batch_size,\n",
        "                'learning_rate': learning_rate,\n",
        "                'max_length': max_length\n",
        "            }, f, indent=2)\n",
        "\n",
        "        print(f\"Entrenamiento completado. Modelo guardado en: {output_dir}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Función principal de ejemplo\"\"\"\n",
        "    # Configuración\n",
        "    ABC_DIRECTORY = \"data_curation/abcs\"  # Directorio con archivos .abc\n",
        "    OUTPUT_DIR = \"./chatmusician-custom\"\n",
        "\n",
        "    # Verificar que existe el directorio\n",
        "    if not os.path.exists(ABC_DIRECTORY):\n",
        "        print(f\"Error: No existe el directorio {ABC_DIRECTORY}\")\n",
        "        print(\"Crea el directorio y coloca tus archivos .abc allí\")\n",
        "        return\n",
        "\n",
        "    # Crear entrenador\n",
        "    trainer = ChatMusicianTrainer()\n",
        "\n",
        "    # Entrenar modelo\n",
        "    trainer.train(\n",
        "        abc_directory=ABC_DIRECTORY,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_epochs=3,\n",
        "        batch_size=2,  # Ajustar según tu GPU\n",
        "        learning_rate=2e-5,\n",
        "        max_length=1536  # Ajustar según el tamaño promedio de tus archivos ABC\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prueba el modelo entrenado"
      ],
      "metadata": {
        "id": "Xab-QZexe2Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "from string import Template\n",
        "import json\n",
        "import os\n",
        "\n",
        "class ChatMusicianTester:\n",
        "    \"\"\"Clase para probar el modelo ChatMusician entrenado\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str):\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.prompt_template = Template(\"Human: ${inst} </s> Assistant: \")\n",
        "\n",
        "        # Configuración de generación\n",
        "        self.generation_config = GenerationConfig(\n",
        "            temperature=0.2,\n",
        "            top_k=40,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            num_beams=1,\n",
        "            repetition_penalty=1.1,\n",
        "            min_new_tokens=10,\n",
        "            max_new_tokens=1536,\n",
        "            pad_token_id=None  # Se configurará después\n",
        "        )\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Carga el modelo entrenado\"\"\"\n",
        "        print(f\"Cargando modelo desde: {self.model_path}\")\n",
        "\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.model_path,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_path,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True\n",
        "            ).eval()\n",
        "\n",
        "            # Configurar pad_token para generation_config\n",
        "            self.generation_config.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "            print(\"Modelo cargado exitosamente\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error cargando el modelo: {e}\")\n",
        "            raise\n",
        "\n",
        "    def generate_music(self, instruction: str, save_audio: bool = True, output_file: str = None) -> str:\n",
        "        \"\"\"Genera música basada en una instrucción\"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            raise ValueError(\"Modelo no cargado. Ejecuta load_model() primero.\")\n",
        "\n",
        "        # Formatear prompt\n",
        "        prompt = self.prompt_template.safe_substitute({\"inst\": instruction})\n",
        "\n",
        "        # Tokenizar\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "\n",
        "        # Generar\n",
        "        with torch.no_grad():\n",
        "            response = self.model.generate(\n",
        "                input_ids=inputs[\"input_ids\"].to(self.model.device),\n",
        "                attention_mask=inputs['attention_mask'].to(self.model.device),\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                generation_config=self.generation_config,\n",
        "            )\n",
        "\n",
        "        # Decodificar respuesta\n",
        "        generated_text = self.tokenizer.decode(\n",
        "            response[0][inputs[\"input_ids\"].shape[1]:],\n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "\n",
        "        print(f\"\\nInstrucción: {instruction}\")\n",
        "        print(f\"Respuesta generada:\\n{generated_text}\")\n",
        "\n",
        "        # Renderizar audio si es posible\n",
        "        if save_audio:\n",
        "            self._render_audio(generated_text, output_file or \"generated_music.wav\")\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    def _render_audio(self, response_text: str, output_file: str):\n",
        "        \"\"\"Renderiza ABC notation a audio usando symusic\"\"\"\n",
        "        try:\n",
        "            # Importar symusic\n",
        "            from symusic import Score, Synthesizer, BuiltInSF3, dump_wav\n",
        "\n",
        "            # Extraer notación ABC\n",
        "            abc_pattern = r'(X:\\d+\\n(?:[^\\n]*\\n?)+)'\n",
        "            abc_matches = re.findall(abc_pattern, response_text + '\\n')\n",
        "\n",
        "            if abc_matches:\n",
        "                abc_notation = abc_matches[0]\n",
        "                print(f\"\\nNotación ABC extraída:\\n{abc_notation}\")\n",
        "\n",
        "                # Convertir a Score y renderizar\n",
        "                try:\n",
        "                    score = Score.from_abc(abc_notation)\n",
        "                    synthesizer = Synthesizer()\n",
        "                    audio = synthesizer.render(score, stereo=True)\n",
        "\n",
        "                    # Guardar audio\n",
        "                    torchaudio.save(output_file, torch.FloatTensor(audio), 44100)\n",
        "                    print(f\"Audio guardado en: {output_file}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error renderizando audio: {e}\")\n",
        "                    print(\"Verifica que la notación ABC sea válida\")\n",
        "            else:\n",
        "                print(\"No se encontró notación ABC válida en la respuesta\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"symusic no está instalado. Instálalo con: pip install symusic\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error renderizando audio: {e}\")\n",
        "\n",
        "    def run_test_suite(self):\n",
        "        \"\"\"Ejecuta una suite de pruebas del modelo\"\"\"\n",
        "        print(\"=== SUITE DE PRUEBAS CHATMUSICIAN ===\\n\")\n",
        "\n",
        "        test_instructions = [\n",
        "            # Generación básica\n",
        "            \"Compone una melodía sencilla en Do mayor con métrica 4/4\",\n",
        "\n",
        "            # Generación con estilo\n",
        "            \"Crea un jig irlandés en Re mayor\",\n",
        "\n",
        "            # Generación con progresión de acordes\n",
        "            \"Desarrolla una pieza musical usando la progresión de acordes: 'Dm', 'C', 'Dm', 'Dm', 'C', 'Dm', 'C', 'Dm'\",\n",
        "\n",
        "            # Generación influencia de compositor\n",
        "            \"Desarrolla una melodía influenciada por las composiciones de Bach\",\n",
        "\n",
        "            # Análisis musical\n",
        "            \"\"\"Analiza esta pieza musical y describe su estructura:\n",
        "X:1\n",
        "T:Ejemplo de Análisis\n",
        "M:4/4\n",
        "L:1/8\n",
        "K:G\n",
        "|: G2 AB c2 d2 | e2 dc B2 A2 | G2 AB c2 d2 | e2 d2 c4 :|\n",
        "|: e2 fg a2 g2 | f2 ed c2 B2 | A2 Bc d2 c2 | B2 A2 G4 :|\"\"\",\n",
        "        ]\n",
        "\n",
        "        results = []\n",
        "\n",
        "        for i, instruction in enumerate(test_instructions, 1):\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"PRUEBA {i}/{len(test_instructions)}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            try:\n",
        "                result = self.generate_music(\n",
        "                    instruction,\n",
        "                    save_audio=True,\n",
        "                    output_file=f\"test_output_{i}.wav\"\n",
        "                )\n",
        "                results.append({\n",
        "                    'test_id': i,\n",
        "                    'instruction': instruction,\n",
        "                    'result': result,\n",
        "                    'status': 'success'\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error en prueba {i}: {e}\")\n",
        "                results.append({\n",
        "                    'test_id': i,\n",
        "                    'instruction': instruction,\n",
        "                    'result': str(e),\n",
        "                    'status': 'error'\n",
        "                })\n",
        "\n",
        "        # Guardar resultados\n",
        "        with open('test_results.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(\"RESUMEN DE PRUEBAS COMPLETADO\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        successful_tests = sum(1 for r in results if r['status'] == 'success')\n",
        "        print(f\"Pruebas exitosas: {successful_tests}/{len(results)}\")\n",
        "        print(\"Resultados guardados en: test_results.json\")\n",
        "\n",
        "    def interactive_mode(self):\n",
        "        \"\"\"Modo interactivo para probar el modelo\"\"\"\n",
        "        print(\"=== MODO INTERACTIVO CHATMUSICIAN ===\")\n",
        "        print(\"Escribe tus instrucciones musicales (escribe 'quit' para salir)\")\n",
        "        print(\"Ejemplos:\")\n",
        "        print(\"- Compone una balada en La menor\")\n",
        "        print(\"- Crea un vals en Mi bemol mayor\")\n",
        "        print(\"- Genera variaciones de este tema: [notación ABC]\")\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "        counter = 1\n",
        "        while True:\n",
        "            try:\n",
        "                instruction = input(f\"\\nInstrucción {counter}: \").strip()\n",
        "\n",
        "                if instruction.lower() in ['quit', 'exit', 'salir']:\n",
        "                    print(\"¡Hasta luego!\")\n",
        "                    break\n",
        "\n",
        "                if not instruction:\n",
        "                    continue\n",
        "\n",
        "                print(\"\\nGenerando...\")\n",
        "                result = self.generate_music(\n",
        "                    instruction,\n",
        "                    save_audio=True,\n",
        "                    output_file=f\"interactive_output_{counter}.wav\"\n",
        "                )\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n\\n¡Hasta luego!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Función principal\"\"\"\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Probar modelo ChatMusician entrenado\")\n",
        "    parser.add_argument(\"--model_path\", required=True, help=\"Ruta al modelo entrenado\")\n",
        "    parser.add_argument(\"--mode\", choices=['test', 'interactive', 'single'],\n",
        "                      default='test', help=\"Modo de ejecución\")\n",
        "    parser.add_argument(\"--instruction\", help=\"Instrucción única para modo 'single'\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Verificar que existe el modelo\n",
        "    if not os.path.exists(args.model_path):\n",
        "        print(f\"Error: No existe el directorio del modelo: {args.model_path}\")\n",
        "        return\n",
        "\n",
        "    # Crear tester\n",
        "    tester = ChatMusicianTester(args.model_path)\n",
        "\n",
        "    try:\n",
        "        # Cargar modelo\n",
        "        tester.load_model()\n",
        "\n",
        "        # Ejecutar según el modo\n",
        "        if args.mode == 'test':\n",
        "            tester.run_test_suite()\n",
        "        elif args.mode == 'interactive':\n",
        "            tester.interactive_mode()\n",
        "        elif args.mode == 'single':\n",
        "            if not args.instruction:\n",
        "                print(\"Error: Se requiere --instruction para el modo 'single'\")\n",
        "                return\n",
        "            tester.generate_music(args.instruction)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error ejecutando el tester: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zma9vUHlezv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}